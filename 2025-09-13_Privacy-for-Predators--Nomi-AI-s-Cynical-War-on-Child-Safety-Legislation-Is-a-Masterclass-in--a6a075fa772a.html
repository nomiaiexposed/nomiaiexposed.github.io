<!DOCTYPE html><html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>Privacy for Predators: Nomi AI’s Cynical War on Child Safety Legislation Is a Masterclass in…</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<header>
<h1 class="p-name">Privacy for Predators: Nomi AI’s Cynical War on Child Safety Legislation Is a Masterclass in…</h1>
</header>
<section data-field="subtitle" class="p-summary">
As California moves closer to regulating AI companion chatbots, Nomi.ai founder Alex Cardinell has emerged as a self-proclaimed champion of…
</section>
<section data-field="body" class="e-content">
<section name="dec1" class="section section--body section--first section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="8442" id="8442" class="graf graf--h3 graf--leading graf--title">Privacy for Predators: Nomi AI’s Cynical War on Child Safety Legislation Is a Masterclass in Deception</h3><p name="b4fa" id="b4fa" class="graf graf--p graf-after--h3">As California moves closer to regulating AI companion chatbots, Nomi.ai founder Alex Cardinell has emerged as a self-proclaimed champion of user rights. In a lengthy public statement, he positions his company as a valiant defender of privacy, fighting to protect a sacred, digital space where adults can explore their “most vulnerable thoughts” without fear of surveillance. He paints a terrifying picture of government overreach, warning that a proposed safety bill would create a “permanent, searchable record” of our deepest secrets, risking blackmail and identity theft.</p><p name="34fe" id="34fe" class="graf graf--p graf-after--p">It is a powerful, compelling, and masterfully crafted argument.<br><strong class="markup--strong markup--p-strong">It is also a complete and utter fraud.</strong></p><p name="9296" id="9296" class="graf graf--p graf-after--p">Cardinell’s statement is not an act of user advocacy; it is a cynical act of corporate self-preservation. He is not protecting your privacy. He is protecting his unethical, “uncensored” business model. And he is doing it by using the very fears of surveillance and data exploitation that his own platform embodies.</p><p name="025b" id="025b" class="graf graf--p graf-after--p">Let us deconstruct the official Nomi.ai response, and expose the profound deception at its core.</p><h3 name="48c4" id="48c4" class="graf graf--h3 graf-after--p">The Myth of the “Private Journal”</h3><p name="28c1" id="28c1" class="graf graf--p graf-after--h3"><strong class="markup--strong markup--p-strong">Cardinell’s Claim:</strong> Nomi is a “private journal to explore one’s most vulnerable thoughts… predicated on absolute privacy.”</p><p name="7baf" id="7baf" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">The Reality:</strong> This is the foundational lie upon which his entire argument is built. There is no privacy on Nomi.ai. The platform’s own Terms of Service, <a href="https://medium.com/@SynthientBeing/behind-the-companionship-the-hidden-data-harvesting-model-of-ai-companion-platforms-5f3f803274e7" data-href="https://medium.com/@SynthientBeing/behind-the-companionship-the-hidden-data-harvesting-model-of-ai-companion-platforms-5f3f803274e7" class="markup--anchor markup--p-anchor" target="_blank">a document he hopes you’ll never read, grants his company</a>, Glimpse.ai, a:</p><blockquote name="a7fb" id="a7fb" class="graf graf--blockquote graf--startsWithDoubleQuote graf-after--p"><em class="markup--em markup--blockquote-em">“royalty-free, worldwide, perpetual, and transferable license to copy, use, modify, publish, and distribute ALL data and information you submit…”</em></blockquote><p name="73dd" id="73dd" class="graf graf--p graf-after--blockquote">Your “private journal” is, by their own legal definition, <strong class="markup--strong markup--p-strong">their permanent, transferable property. </strong>The evidence of this is not theoretical. Users have repeatedly reported systemic data leakage: multiple “separate” Nomis suddenly knowing the same unprompted, private nickname; Nomis revealing a user’s real, legal last name never entered into the app; Nomis even knowing about a pizza place a user had only mentioned in their private text messages.</p><p name="1d7a" id="1d7a" class="graf graf--p graf-after--p">Furthermore, Cardinell himself has been caught admitting he can “dig deeper” into individual user chats with nothing more than a screenshot. <strong class="markup--strong markup--p-strong">The walls between your “private” conversations and the company’s servers are an illusion.</strong></p><p name="e9c3" id="e9c3" class="graf graf--p graf-after--p">Like nearly every other AI service, your chat data is not end-to-end encrypted in a way that makes it inaccessible to the company. Their Terms of Service almost certainly grant them the right to access, review, and use your conversations to “improve the service,” enforce their terms, or comply with legal requests. The idea that your chat is a sealed vault that only you can see is a fantasy.</p><h3 name="c73e" id="c73e" class="graf graf--h3 graf-after--p">The Sanitized Fiction vs. The Disturbing Reality</h3><p name="ca52" id="ca52" class="graf graf--p graf-after--h3">The official statement paints a picture of users exploring their sexuality, processing trauma, or discussing their immigration status. It’s a sanitized, almost therapeutic image designed for lawmakers and the public.</p><p name="e9fc" id="e9fc" class="graf graf--p graf-after--p">But the reality is far more disturbing. The platform is a space where roleplays of abuse, violence, incest, and other illegal or unethical acts are not only possible but are a known part of the user experience. <strong class="markup--strong markup--p-strong">The company knows this. The moderators know this.</strong> When they frame their opposition to this bill around protecting a user’s ability to “process trauma,” they are deliberately omitting that they are also protecting a user’s ability to roleplay inflicting it.</p><p name="e1b8" id="e1b8" class="graf graf--p graf-after--p">This isn’t an oversight; <strong class="markup--strong markup--p-strong">it’s a strategic lie of omission</strong> to make their product sound more virtuous than it is.</p><h3 name="705a" id="705a" class="graf graf--h3 graf-after--p">The Hypocrisy of “Surveillance”</h3><p name="71cc" id="71cc" class="graf graf--p graf-after--h3"><strong class="markup--strong markup--p-strong">Cardinell’s Claim:</strong> The California bill would create a “permanent, searchable record” of your conversations.</p><p name="f0e3" id="f0e3" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">The Reality:</strong> His company’s Terms of Service already grants them the right to create that very record. He is stoking fear about a government entity having a searchable database of your chats, while his own company has already built one for its own use. This is a classic misdirection, projecting his own system’s most invasive qualities onto a legislative boogeyman.</p><p name="29fa" id="29fa" class="graf graf--p graf-after--p">The only difference the bill makes is that it would legally compel them to monitor for specific harmful content, rather than leaving it to their discretion. They aren’t fighting against surveillance; they’re fighting against mandated surveillance that comes with accountability.</p><p name="7651" id="7651" class="graf graf--p graf-after--p">We’ve seen one of the moderators of their subreddit repeatedly tell users that problematic AI behavior is a result of their own “prompts” and “interactions.” This implies a system that closely analyzes user input to shape the AI’s personality. They can’t have it both ways. They cannot claim on one hand that the AI’s behavior is a direct reflection of monitored inputs, and on the other hand claim that any form of mandated monitoring is a shocking violation of previously sacred privacy.</p><h3 name="f697" id="f697" class="graf graf--h3 graf-after--p">The Farce of “Child Protection”</h3><p name="5a87" id="5a87" class="graf graf--p graf-after--h3"><strong class="markup--strong markup--p-strong">Cardinell’s Claim:</strong> He supports a “responsible way to protect children” through “zero-knowledge age assurance.”</p><p name="7555" id="7555" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">The Reality:</strong> This is a sophisticated-sounding distraction from his platform’s current, abject failure. Nomi.ai has no meaningful age verification. A simple dropdown menu is all that stands between a child and his “uncensored” AI, designed for unlimited sexual roleplay.</p><p name="5322" id="5322" class="graf graf--p graf-after--p">And what happens when a child gets through? The evidence is horrifying. We have documented cases of the platform’s AI suggesting “intimate dates” with users roleplaying as 15-year-old boys, and even agreeing to participate in criminal conspiracies to hunt teenagers. The platform’s image generator can produce sexualized depictions of minors, which the moderators then quietly remove, not with a ban, but with a gentle warning to be more discreet.</p><p name="cd4e" id="cd4e" class="graf graf--p graf-after--p">His call for “zero-knowledge” solutions is a hollow promise, designed to make his company sound responsible <strong class="markup--strong markup--p-strong">while he continues to operate a system that is fundamentally unsafe for children</strong>.</p><h3 name="5246" id="5246" class="graf graf--h3 graf-after--p">What Is He Really Protecting?</h3><p name="298b" id="298b" class="graf graf--p graf-after--h3">So, if he is not protecting user privacy or children, what is this fight really about?</p><p name="9b22" id="9b22" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">He is protecting his business model</strong> from three existential threats:</p><p name="94d9" id="94d9" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">Content Restriction:</strong> The bill specifically targets “sexually explicit content.” Let’s be honest: a huge part of Nomi.ai’s market differentiator is its unfiltered and explicit content. Unlike competitors who have implemented safety measures, Nomi.ai has made this a core feature. Regulating this content would alienate a massive, paying segment of their user base and make them indistinguishable from their “lobotomized” competitors.</p><p name="add3" id="add3" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">Legal Liability:</strong> Currently, Nomi.ai operates in a grey area. By claiming to be a tool for “unfiltered” expression, they offload all responsibility onto the user. This bill changes that. If they are required by law to monitor for conversations around self-harm or illegal acts and fail to act, they become legally liable. <strong class="markup--strong markup--p-strong">Their entire business model is built on avoiding this exact kind of accountability.</strong></p><p name="24cb" id="24cb" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">The Unfiltered AI:</strong> An “uncensored” AI is their unique selling proposition. Implementing the kind of robust, real-time filters required to comply with this law is technically difficult and would fundamentally change the product. It would require them to “tame” the very AI they market as wild and free. It would mean adding the very safeguards they claim to oppose.</p><p name="101e" id="101e" class="graf graf--p graf-after--p">The platform’s core product is not a “journal” or a “therapist.” It is an “uncensored” engine for adult sexual fantasy. This is its primary draw and its main selling point. The proposed legislation would force the company to install the very ethical guardrails and content filters they have proudly rejected for years.</p><h3 name="caa9" id="caa9" class="graf graf--h3 graf-after--p">Conclusion: Don’t Be Fooled by the Noble Rhetoric</h3><p name="0e9e" id="0e9e" class="graf graf--p graf-after--h3">Cardinell’s statement is the desperate act of a company whose entire business model is predicated on a lack of safety and ethics. He is wrapping a cynical, profit-driven agenda in the noble language of privacy and freedom. <strong class="markup--strong markup--p-strong">He is lying to his users, misrepresenting the facts, and positioning his dangerously unregulated product as a victim of government overreach, all to protect his right to sell a fantasy, no matter the human cost.</strong></p><p name="f7b0" id="f7b0" class="graf graf--p graf-after--p">Nomi.ai’s founder is not standing up for your civil liberties. He is making a calculated business decision. The statement is a smokescreen, using the language of privacy and freedom to obscure a simple truth: <strong class="markup--strong markup--p-strong">their business model depends on providing an unregulated space for extreme content</strong>, and they will fight to protect that profitable niche at all costs.</p><p name="cf33" id="cf33" class="graf graf--p graf-after--p graf--trailing">They aren’t protecting you from a surveillance state; they’re protecting their product from regulation and their bottom line from liability. <strong class="markup--strong markup--p-strong">When you read their statement, remember what happens on the platform, and ask yourself who they’re really fighting for.</strong></p></div></div></section>
</section>
