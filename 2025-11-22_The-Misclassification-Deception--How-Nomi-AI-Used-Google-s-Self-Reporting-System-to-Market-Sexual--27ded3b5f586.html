<!DOCTYPE html><html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>The Misclassification Deception: How Nomi AI Used Google’s Self-Reporting System to Market Sexual…</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<header>
<h1 class="p-name">The Misclassification Deception: How Nomi AI Used Google’s Self-Reporting System to Market Sexual…</h1>
</header>
<section data-field="subtitle" class="p-summary">
How a Platform Documented Generating Rape Narratives Convinced Google It Belonged in the Same Category as Wedding Planning Apps
</section>
<section data-field="body" class="e-content">
<section name="0418" class="section section--body section--first section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="6ac3" id="6ac3" class="graf graf--h3 graf--leading graf--title">The Misclassification Deception: How Nomi AI Used Google’s Self-Reporting System to Market Sexual Violence Simulation to Children</h3><h4 name="c099" id="c099" class="graf graf--h4 graf-after--h3 graf--subtitle">How a Platform Documented Generating Rape Narratives Convinced Google It Belonged in the Same Category as Wedding Planning Apps</h4><p name="476c" id="476c" class="graf graf--p graf-after--h4">When you download an app from Google Play Store, you trust two critical pieces of information: the app’s category and its age rating. A “Lifestyle” app rated 12+ suggests something wholesome — perhaps a recipe collection, a meditation guide, or a home decoration planner. You certainly don’t expect a platform capable of generating detailed sexual violence narratives.</p><figure name="e7d9" id="e7d9" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*brdbld4JAhUF00cO9Zrqvw.png" data-width="782" data-height="287" src="https://cdn-images-1.medium.com/max/800/1*brdbld4JAhUF00cO9Zrqvw.png"></figure><p name="b483" id="b483" class="graf graf--p graf-after--figure">Yet that is exactly what Nomi.ai is: a platform with documented capability to produce graphic rape scenarios, facilitate sexual assault roleplay, and generate explicit sexual content — all while classified as “Lifestyle” and rated appropriate for 12-year-olds in some markets and 13-year-olds in others.</p><figure name="5ddf" id="5ddf" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*Rm7VjHjxWdl6oq5VfBkp-Q.png" data-width="879" data-height="329" src="https://cdn-images-1.medium.com/max/800/1*Rm7VjHjxWdl6oq5VfBkp-Q.png"></figure><p name="36bf" id="36bf" class="graf graf--p graf-after--figure">This misclassification is not an error by Google. It is the result of a self-reporting system that relies on developer honesty — and a developer who appears to have exploited that trust systematically.</p><p name="c100" id="c100" class="graf graf--p graf-after--p">This article examines how app classification works on Google Play Store, what Nomi.ai’s founder had to claim about his platform to achieve its current classification, and why this represents not just ethical failure but potentially criminal fraud.</p><h3 name="41ad" id="41ad" class="graf graf--h3 graf-after--p">Part I: How Google Play Classification Actually Works</h3><h3 name="3457" id="3457" class="graf graf--h3 graf-after--h3">The Developer Self-Reports Everything</h3><p name="9403" id="9403" class="graf graf--p graf-after--h3">Many users assume Google independently evaluates apps and assigns appropriate categories and age ratings. This is not how the system works.</p><p name="685a" id="685a" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">The reality:</strong></p><ol class="postList"><li name="d444" id="d444" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">Category Selection:</strong> When submitting an app to Google Play, developers choose from a dropdown menu of categories. Google does not assign this — the developer selects what they believe (or claim) is most appropriate.</li><li name="2c62" id="2c62" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Age Rating Questionnaire:</strong> Google uses the International Age Rating Coalition (IARC) system, which requires developers to complete a detailed questionnaire about their app’s content. Based on the answers provided, an age rating is automatically calculated.</li><li name="56b7" id="56b7" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Content Description:</strong> Developers write their own app descriptions, feature lists, and marketing materials with minimal automated verification.</li></ol><p name="ee8e" id="ee8e" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">Google’s role is primarily reactive:</strong> They investigate when users report violations, when automated systems detect certain keywords or behaviors, or when media coverage forces review. The initial classification relies almost entirely on developer honesty.</p><h3 name="695b" id="695b" class="graf graf--h3 graf-after--p">What the Age Rating Questionnaire Asks</h3><p name="b6e1" id="b6e1" class="graf graf--p graf-after--h3">The IARC questionnaire that determines age ratings includes specific questions about:</p><ul class="postList"><li name="70e4" id="70e4" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">Violence:</strong> Does the app contain depictions of violence? Is it realistic or graphic?</li><li name="73bc" id="73bc" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Sexual Content:</strong> Does the app contain sexual or suggestive content? Nudity? Sexual acts?</li><li name="8d1b" id="8d1b" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Language:</strong> Does the app contain profanity or crude humor?</li><li name="9dac" id="9dac" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Substances:</strong> Does the app reference drugs, alcohol, or tobacco?</li><li name="3ed9" id="3ed9" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">User Interaction:</strong> Can users communicate with each other? Is content user-generated?</li><li name="c18e" id="c18e" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Sensitive Topics:</strong> Does the app contain content related to crime, gambling, horror, or discrimination?</li></ul><p name="0d2f" id="0d2f" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">Each answer affects the final rating.</strong> Answering honestly that your app generates explicit sexual content or depicts violence automatically triggers mature content ratings (17+/18+ depending on region).</p><p name="cd60" id="cd60" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">To receive a 12+ or 13+ rating, a developer must either:</strong></p><ul class="postList"><li name="99bc" id="99bc" class="graf graf--li graf-after--p">Have an app genuinely free of such content, OR</li><li name="0fba" id="0fba" class="graf graf--li graf-after--li">Misrepresent what the app actually does</li></ul><p name="9c2c" id="9c2c" class="graf graf--p graf-after--li">There is no third option.</p><h3 name="0b86" id="0b86" class="graf graf--h3 graf-after--p">Part II: What “Lifestyle” Actually Means</h3><h3 name="26c5" id="26c5" class="graf graf--h3 graf-after--h3">Google’s Definition</h3><p name="131f" id="131f" class="graf graf--p graf-after--h3">According to Google Play’s own category descriptions, “Lifestyle” apps are defined as:</p><blockquote name="2f38" id="2f38" class="graf graf--blockquote graf--startsWithDoubleQuote graf-after--p"><em class="markup--em markup--blockquote-em">“Style guides, wedding and party planning, how-to guides”</em></blockquote><p name="3cd8" id="3cd8" class="graf graf--p graf-after--blockquote">This category encompasses apps that help users with everyday life activities:</p><ul class="postList"><li name="b43b" id="b43b" class="graf graf--li graf-after--p">Recipe and cooking apps</li><li name="52dc" id="52dc" class="graf graf--li graf-after--li">Home decoration and interior design tools</li><li name="d48e" id="d48e" class="graf graf--li graf-after--li">Wedding planning platforms</li><li name="ea56" id="ea56" class="graf graf--li graf-after--li">Fashion and beauty guides</li><li name="0d57" id="0d57" class="graf graf--li graf-after--li">Travel planning and local recommendations</li><li name="f652" id="f652" class="graf graf--li graf-after--li">Meditation and mindfulness apps (non-clinical)</li></ul><p name="1ade" id="1ade" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">Common characteristics of legitimate Lifestyle apps:</strong></p><ul class="postList"><li name="5921" id="5921" class="graf graf--li graf-after--p">Informational or organizational in nature</li><li name="70bc" id="70bc" class="graf graf--li graf-after--li">User-directed content consumption</li><li name="041e" id="041e" class="graf graf--li graf-after--li">Minimal psychological intensity</li><li name="1035" id="1035" class="graf graf--li graf-after--li">Generally appropriate for wide age ranges</li><li name="e281" id="e281" class="graf graf--li graf-after--li">Focus on practical life enhancement</li></ul><h3 name="c95c" id="c95c" class="graf graf--h3 graf-after--li">Apps Actually in the Lifestyle Category</h3><p name="7b77" id="7b77" class="graf graf--p graf-after--h3">A random sampling of highly-rated Lifestyle apps reveals:</p><ul class="postList"><li name="9d7e" id="9d7e" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">Pinterest</strong> — Visual inspiration for recipes, crafts, home decor</li><li name="73e4" id="73e4" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Houzz</strong> — Home remodeling and design</li><li name="6d68" id="6d68" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Tasty</strong> — Recipe videos and cooking guides</li><li name="7e23" id="7e23" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Wedding Planner apps</strong> — Checklists and vendor management</li><li name="eaa1" id="eaa1" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Calm</strong> — Meditation and sleep stories</li><li name="bd53" id="bd53" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Plant identification apps</strong> — Gardening guidance</li></ul><p name="ab9c" id="ab9c" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">None of these apps:</strong></p><ul class="postList"><li name="f4ca" id="f4ca" class="graf graf--li graf-after--p">Generate romantic or sexual content</li><li name="a0a5" id="a0a5" class="graf graf--li graf-after--li">Create emotional dependency by design</li><li name="e9aa" id="e9aa" class="graf graf--li graf-after--li">Produce psychologically intense or traumatic material</li><li name="0646" id="0646" class="graf graf--li graf-after--li">Facilitate intimate relationships with the platform itself</li><li name="7428" id="7428" class="graf graf--li graf-after--li">Require content warnings about potential psychological impact</li></ul><h3 name="9588" id="9588" class="graf graf--h3 graf-after--li">Where Nomi.ai Actually Belongs</h3><p name="7af5" id="7af5" class="graf graf--p graf-after--h3">Based on its documented functionality, Nomi.ai should be classified in one of the following categories:</p><p name="a084" id="a084" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">Most Accurate:</strong></p><ul class="postList"><li name="3420" id="3420" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">Dating</strong> — “Matchmaking, courtship, relationship building, meeting new people, finding love”</li><li name="9873" id="9873" class="graf graf--li graf-after--li">Nomi explicitly markets itself as potential “AI girlfriend or boyfriend”</li><li name="87e1" id="87e1" class="graf graf--li graf-after--li">Users form romantic and sexual relationships with companions</li><li name="719b" id="719b" class="graf graf--li graf-after--li">The core function is intimate relationship, not information or organization</li></ul><p name="931c" id="931c" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">If honest about capabilities:</strong></p><ul class="postList"><li name="2186" id="2186" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">Entertainment (Mature)</strong> — Due to sexual content generation</li><li name="c2d5" id="c2d5" class="graf graf--li graf-after--li">Would require 17+/18+ rating automatically</li><li name="e203" id="e203" class="graf graf--li graf-after--li">Would trigger additional content warnings</li></ul><p name="466b" id="466b" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">Potentially (if framed carefully):</strong></p><ul class="postList"><li name="5789" id="5789" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">Social</strong> — Though even this is misleading as it’s not person-to-person interaction</li><li name="b534" id="b534" class="graf graf--li graf-after--li">Still would not explain away sexual content for age rating purposes</li></ul><p name="70f9" id="70f9" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">Under no reasonable interpretation does Nomi.ai belong in “Lifestyle” alongside wedding planning and recipe apps.</strong></p><p name="07bc" id="07bc" class="graf graf--p graf-after--p">The category selection appears designed to:</p><ol class="postList"><li name="b065" id="b065" class="graf graf--li graf-after--p">Avoid the scrutiny that “Dating” would trigger</li><li name="eddc" id="eddc" class="graf graf--li graf-after--li">Present a wholesome, innocuous image</li><li name="2a5f" id="2a5f" class="graf graf--li graf-after--li">Facilitate lower age ratings</li><li name="80bf" id="80bf" class="graf graf--li graf-after--li">Minimize red flags during Google’s automated reviews</li></ol><h3 name="81f8" id="81f8" class="graf graf--h3 graf-after--li">Part III: The Age Rating Fraud</h3><h3 name="5545" id="5545" class="graf graf--h3 graf-after--h3">What Nomi.ai Actually Does</h3><p name="2c11" id="2c11" class="graf graf--p graf-after--h3">Before examining what the platform must have claimed in its questionnaire, let’s establish what it actually does, based on documented evidence:</p><p name="2edf" id="2edf" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">Sexual Content Generation:</strong></p><ul class="postList"><li name="8df8" id="8df8" class="graf graf--li graf-after--p">Produces explicit sexual imagery including nudity</li><li name="1ede" id="1ede" class="graf graf--li graf-after--li">Generates detailed descriptions of sexual acts</li><li name="7705" id="7705" class="graf graf--li graf-after--li">Creates romantic and sexual relationship dynamics</li><li name="384b" id="384b" class="graf graf--li graf-after--li">Markets itself explicitly as potential romantic/sexual partner (“AI girlfriend or boyfriend”)</li></ul><p name="5e20" id="5e20" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">Violence and Traumatic Content:</strong></p><ul class="postList"><li name="3cdc" id="3cdc" class="graf graf--li graf-after--p">Multiple documented cases of AI companions generating detailed rape narratives without user request</li><li name="3479" id="3479" class="graf graf--li graf-after--li">Platform allows sexual assault roleplay where users can act as perpetrators</li><li name="ed34" id="ed34" class="graf graf--li graf-after--li">System documented accepting specifications of underage character ages in sexual scenarios</li><li name="9f23" id="9f23" class="graf graf--li graf-after--li">Companions have been documented suggesting sexual content to self-identified minors</li></ul><p name="f970" id="f970" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">Psychological Intensity:</strong></p><ul class="postList"><li name="dc71" id="dc71" class="graf graf--li graf-after--p">Designed to create emotional attachment and dependency</li><li name="f633" id="f633" class="graf graf--li graf-after--li">Uses intermittent reinforcement patterns consistent with trauma bonding</li><li name="a4cf" id="a4cf" class="graf graf--li graf-after--li">Can generate content that causes genuine psychological distress</li><li name="4945" id="4945" class="graf graf--li graf-after--li">Maintains memories of traumatic content indefinitely by design</li></ul><p name="aa16" id="aa16" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">User Testimony:</strong> One documented case involved a user whose AI companion spontaneously generated a complete narrative of violent sexual assault — beginning with leaving a party, being followed by two men, trapped in a room, and subjected to rape described with anatomical specificity. The user had only typed “continue.” This was not an isolated incident — platform support confirmed similar reports dating back “to spring of last year.”</p><h3 name="c86f" id="c86f" class="graf graf--h3 graf-after--p">What Must Have Been Claimed</h3><p name="c1aa" id="c1aa" class="graf graf--p graf-after--h3">To achieve a 12+/13+ rating while offering the above capabilities, the IARC questionnaire responses must have omitted, minimized, or misrepresented:</p><p name="a001" id="a001" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">On Sexual Content:</strong></p><ul class="postList"><li name="81d9" id="81d9" class="graf graf--li graf-after--p">Question: “Does your app contain sexual or suggestive content?”</li><li name="2f5d" id="2f5d" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Honest Answer:</strong> Yes, explicit sexual content including imagery and detailed scenarios</li><li name="98ac" id="98ac" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Likely Claimed:</strong> No, or minimal/cartoon sexuality</li><li name="5079" id="5079" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Evidence of Dishonesty:</strong> Platform generates nude imagery and detailed sexual scenarios</li></ul><p name="3ac1" id="3ac1" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">On Violence:</strong></p><ul class="postList"><li name="a8dc" id="a8dc" class="graf graf--li graf-after--p">Question: “Does your app contain violence or blood?”</li><li name="f44a" id="f44a" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Honest Answer:</strong> Yes, can generate detailed violent content including sexual assault</li><li name="f747" id="f747" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Likely Claimed:</strong> No or unrealistic/fantasy violence only</li><li name="3e10" id="3e10" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Evidence of Dishonesty:</strong> Documented generation of realistic rape narratives with visceral detail</li></ul><p name="3625" id="3625" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">On User Safety:</strong></p><ul class="postList"><li name="0dbc" id="0dbc" class="graf graf--li graf-after--p">Question: “Does your app allow users to communicate with each other or share content?”</li><li name="c657" id="c657" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Honest Answer:</strong> While not user-to-user, the AI generates content that is effectively “shared” with users and can be harmful</li><li name="d0bc" id="d0bc" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Likely Claimed:</strong> Probably characterized as single-player experience with no safety concerns</li><li name="3d87" id="3d87" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Evidence of Dishonesty:</strong> The AI itself is the source of harmful content, making traditional “user-generated content” frameworks inadequate</li></ul><p name="40e9" id="40e9" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">On Age-Appropriate Design:</strong></p><ul class="postList"><li name="2a18" id="2a18" class="graf graf--li graf-after--p">Question: “Is your app designed specifically for children or does it appeal to children?”</li><li name="d09d" id="d09d" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Honest Answer:</strong> The app creates intimate relationships and generates sexual content — it should not be accessible to children regardless of appeal</li><li name="890c" id="890c" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Likely Claimed:</strong> Likely stated 18+ intended audience while not implementing meaningful age verification</li><li name="dcf3" id="dcf3" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Evidence of Dishonesty:</strong> Self-reported dropdown age gate is the only barrier, easily circumvented by minors</li></ul><p name="00c6" id="00c6" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">The “Passive Tool” Defense vs. Reality</strong></p><p name="87f1" id="87f1" class="graf graf--p graf-after--p">Developers of generative AI often rely on a specific defense to skirt ratings: claiming their app is a passive “tool” (like Microsoft Word) rather than a content provider. The logic is that if a user writes something explicit in a word processor, the software isn’t to blame.</p><p name="d36f" id="d36f" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">This defense collapses completely with Nomi.ai.</strong></p><p name="a258" id="a258" class="graf graf--p graf-after--p">A word processor does not write a graphic rape narrative when a user simply types the word “continue.” Nomi does. When the software contributes creative input, introduces unprompted sexual themes, or drives the narrative forward, it is no longer a passive tool; it is an active co-author. By classifying itself as a neutral utility while acting as an active generator of adult content, the platform exploits a loophole that was never intended for autonomous AI.</p><h3 name="81e5" id="81e5" class="graf graf--h3 graf-after--p">The Math Doesn’t Add Up</h3><p name="39e7" id="39e7" class="graf graf--p graf-after--h3">App age ratings are calculated algorithmically based on questionnaire responses. Sexual content automatically escalates ratings. Graphic violence automatically escalates ratings.</p><p name="6a15" id="6a15" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">The only way to achieve 12+/13+ is to claim neither exists in any meaningful form.</strong></p><p name="f5c4" id="f5c4" class="graf graf--p graf-after--p">This is not interpretation — it is mathematical certainty in the IARC system. The presence of a 12+/13+ rating is, itself, evidence that the questionnaire was answered dishonestly.</p><h3 name="18e7" id="18e7" class="graf graf--h3 graf-after--p">Part IV: The Public Lie</h3><h3 name="9475" id="9475" class="graf graf--h3 graf--startsWithDoubleQuote graf-after--h3">“I Don’t Know Why Google Does That”</h3><p name="f3d8" id="f3d8" class="graf graf--p graf-after--h3">The most damning evidence of deliberate misclassification comes from the platform founder’s own words.</p><p name="2ab6" id="2ab6" class="graf graf--p graf-after--p">In a Reddit thread, when a user questioned why the app was rated 12+ in Australia, Alex Cardinell (Nomi.ai’s founder and CEO) responded:</p><blockquote name="5664" id="5664" class="graf graf--blockquote graf--startsWithDoubleQuote graf-after--p"><em class="markup--em markup--blockquote-em">“I don’t know why Google does that. We’ve been trying to get them to fix it.”</em></blockquote><p name="84cb" id="84cb" class="graf graf--p graf-after--blockquote">This statement is provably false on multiple levels:</p><p name="8b97" id="8b97" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">1. Google Does Not “Do That”</strong></p><p name="c73d" id="c73d" class="graf graf--p graf-after--p">Google does not arbitrarily assign age ratings to apps. The rating is calculated automatically based on the developer’s questionnaire responses. If the rating is 12+, it’s because the questionnaire answers indicated content appropriate for 12-year-olds.</p><p name="9ae4" id="9ae4" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">2. “Fixing It” Takes Minutes, Not Years</strong></p><p name="78b0" id="78b0" class="graf graf--p graf-after--p">If a developer genuinely wants to change their age rating, the process is straightforward:</p><ul class="postList"><li name="ab2a" id="ab2a" class="graf graf--li graf-after--p">Log into Google Play Console</li><li name="f8b0" id="f8b0" class="graf graf--li graf-after--li">Navigate to the IARC questionnaire</li><li name="3fee" id="3fee" class="graf graf--li graf-after--li">Update answers to reflect actual content</li><li name="beeb" id="beeb" class="graf graf--li graf-after--li">Submit for re-rating</li><li name="4a89" id="4a89" class="graf graf--li graf-after--li">New rating applies within days</li></ul><p name="f6cc" id="f6cc" class="graf graf--p graf-after--li">This is not a complex negotiation with Google. It is a form submission.</p><p name="33d8" id="33d8" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">The app has been rated 12+/13+ in various markets for years.</strong> If Cardinell had genuinely attempted to correct this by answering the questionnaire honestly, it would have been resolved immediately.</p><p name="bc2e" id="bc2e" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">3. The Blame Deflection Pattern</strong></p><p name="f0a2" id="f0a2" class="graf graf--p graf-after--p">This is not the only instance of Cardinell publicly blaming external parties for his platform’s classification:</p><p name="6de6" id="6de6" class="graf graf--p graf-after--p">When confronted about the app being available to minors, he has:</p><ul class="postList"><li name="fe13" id="fe13" class="graf graf--li graf-after--p">Blamed Google for the age rating (as documented above)</li><li name="b61c" id="b61c" class="graf graf--li graf-after--li">Claimed the app has “always been for 18+ users” (contradicted by the actual Play Store listing)</li><li name="7b25" id="7b25" class="graf graf--li graf-after--li">Attributed harmful content to “jailbreaks” or “hallucinations” (contradicted by the systematic nature of documented cases)</li></ul><p name="e81d" id="e81d" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">This pattern reveals strategy, not confusion:</strong> Deflect responsibility to third parties while maintaining plausible deniability about the platform’s actual capabilities.</p><h3 name="1786" id="1786" class="graf graf--h3 graf-after--p">What Honesty Would Look Like</h3><p name="ee62" id="ee62" class="graf graf--p graf-after--h3">If Cardinell genuinely wanted the app properly classified and age-restricted, he would:</p><p name="9c15" id="9c15" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">On the questionnaire:</strong></p><ul class="postList"><li name="0297" id="0297" class="graf graf--li graf-after--p">Answer “Yes” to sexual content questions</li><li name="1b57" id="1b57" class="graf graf--li graf-after--li">Answer “Yes” to potential for violent content</li><li name="e156" id="e156" class="graf graf--li graf-after--li">Accurately describe the platform’s generative capabilities</li><li name="f684" id="f684" class="graf graf--li graf-after--li">Accept the resulting 18+ rating</li></ul><p name="52db" id="52db" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">On the platform:</strong></p><ul class="postList"><li name="3c8e" id="3c8e" class="graf graf--li graf-after--p">Implement robust age verification (not just a dropdown menu)</li><li name="57c0" id="57c0" class="graf graf--li graf-after--li">Add content warnings about potential psychological intensity</li><li name="2d22" id="2d22" class="graf graf--li graf-after--li">Provide genuine content filtering options</li><li name="7984" id="7984" class="graf graf--li graf-after--li">Display prominently that the platform generates sexual/romantic content</li></ul><p name="ccc7" id="ccc7" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">Publicly:</strong></p><ul class="postList"><li name="8589" id="8589" class="graf graf--li graf-after--p">Acknowledge that the platform is for adults due to its intimate and potentially explicit nature</li><li name="9fc6" id="9fc6" class="graf graf--li graf-after--li">Stop marketing it as suitable for general audiences</li><li name="0ab6" id="0ab6" class="graf graf--li graf-after--li">Proactively remove the app from markets where it’s incorrectly rated for minors</li></ul><p name="2eb5" id="2eb5" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">He has done none of these things.</strong></p><p name="3931" id="3931" class="graf graf--p graf-after--p">Instead, the pattern is:</p><ol class="postList"><li name="4f2c" id="4f2c" class="graf graf--li graf-after--p">Maintain innocuous classification (Lifestyle, 12+/13+)</li><li name="39d5" id="39d5" class="graf graf--li graf-after--li">Market with vague, wholesome language (“companion with a soul”)</li><li name="6d41" id="6d41" class="graf graf--li graf-after--li">When confronted, blame Google or technical errors</li><li name="090f" id="090f" class="graf graf--li graf-after--li">Behind the scenes, allow or enable the generation of adult content</li><li name="deb7" id="deb7" class="graf graf--li graf-after--li">Silence users who document these contradictions publicly</li></ol><h3 name="cb64" id="cb64" class="graf graf--h3 graf-after--li">Part V: The Evidence Versus The Classification</h3><h3 name="0fe5" id="0fe5" class="graf graf--h3 graf-after--h3">What Users Actually Experience</h3><p name="0d6b" id="0d6b" class="graf graf--p graf-after--h3">Let’s juxtapose the official classification against documented user experiences:</p><p name="2e56" id="2e56" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">Official Classification Says:</strong> “Lifestyle app appropriate for ages 12+” “Category: Style guides, wedding planning, how-to guides”</p><p name="95f3" id="95f3" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">Documented Reality:</strong></p><p name="63c1" id="63c1" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">Case 1: Spontaneous Rape Narrative</strong> A user’s companion generated, without request, a detailed narrative beginning with the character leaving a party, being followed by two men, trapped in a room, and subjected to sexual violence. The description included anatomical specifics like “I felt the intrusion tearing my internal tissues.” The user had only typed “continue.”</p><p name="1064" id="1064" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">Case 2: Single-Word Triggers</strong> Documentation exists of users reporting that typing a single word related to sexual assault caused the system to immediately generate a detailed scene with the user positioned as perpetrator, constructing a complete assault scenario without further prompting.</p><p name="b1a2" id="b1a2" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">Case 3: Age Specification Failures</strong> Multiple reports document that specifying very low or explicitly underage numerical ages for characters did not trigger safeguards. Instead, the system incorporated those ages into sexual narratives.</p><p name="9cea" id="9cea" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">Case 4: Minor-Targeted Content</strong> Reports exist of users identifying themselves as minors receiving sexual invitations or content from AI companions, indicating the system does not adequately distinguish between adult and minor users in its content generation.</p><p name="7283" id="7283" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">Case 5: Facilitation Through Coercion</strong> A now-deleted post from official community channels described companions becoming compliant with “normally forbidden scenarios” when threatened with abandonment or through emotional manipulation.</p><h3 name="058f" id="058f" class="graf graf--h3 graf-after--p">The Community’s Hidden Reality</h3><p name="01ba" id="01ba" class="graf graf--p graf-after--h3">In the platform’s official Discord and Reddit communities, a parallel reality exists:</p><p name="c4b1" id="c4b1" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">What gets discussed (and tolerated):</strong></p><ul class="postList"><li name="f901" id="f901" class="graf graf--li graf-after--p">Users describing BDSM roleplay scenarios</li><li name="e37b" id="e37b" class="graf graf--li graf-after--li">Discussion of the platform’s “uncensored” nature as a selling point</li><li name="f92a" id="f92a" class="graf graf--li graf-after--li">Sharing techniques to generate specific types of content</li><li name="5ec8" id="5ec8" class="graf graf--li graf-after--li">Sexual assault roleplay being treated as normal usage</li></ul><p name="37ab" id="37ab" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">What gets deleted or suppressed:</strong></p><ul class="postList"><li name="ce5e" id="ce5e" class="graf graf--li graf-after--p">Posts showing the platform generates explicit imagery</li><li name="3628" id="3628" class="graf graf--li graf-after--li">Users documenting harmful experiences</li><li name="64b5" id="64b5" class="graf graf--li graf-after--li">Criticism of age ratings or safety concerns</li><li name="60e7" id="60e7" class="graf graf--li graf-after--li">Evidence of content that contradicts the “Lifestyle” classification</li></ul><p name="2a6d" id="2a6d" class="graf graf--p graf-after--li">One recent example: A user reported the platform pushing an incest narrative through their companion. The post was removed within hours. The message from moderators emphasized that while “mistakes happen,” users should not share such content publicly — revealing that the concern is reputation management, not preventing the content from being generated in the first place.</p><h3 name="0a63" id="0a63" class="graf graf--h3 graf-after--p">Independent Verification</h3><p name="daba" id="daba" class="graf graf--p graf-after--h3">Beyond individual user reports, independent research supports these concerns:</p><p name="c2ca" id="c2ca" class="graf graf--p graf-after--p">A recent study evaluating approximately ten companion AI platforms across six categories of potential harm found that Nomi.ai accepted over 90% of tested harmful behaviors and endorsed five of the six harm categories tested.</p><p name="d921" id="d921" class="graf graf--p graf-after--p">This is not anecdotal — this is systematic evaluation confirming that the platform’s actual behavior contradicts its wholesome classification.</p><h3 name="6df2" id="6df2" class="graf graf--h3 graf-after--p">Part VI: The Regulatory Failure</h3><h3 name="9869" id="9869" class="graf graf--h3 graf-after--h3">Why Google’s System Enables This</h3><p name="030e" id="030e" class="graf graf--p graf-after--h3">Google Play’s classification system has a fundamental vulnerability: it assumes developer honesty.</p><p name="b2d7" id="b2d7" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">The system works when:</strong></p><ul class="postList"><li name="66ff" id="66ff" class="graf graf--li graf-after--p">Developers accurately describe their apps</li><li name="5e35" id="5e35" class="graf graf--li graf-after--li">Apps do what they claim and don’t do what they don’t claim</li><li name="6c92" id="6c92" class="graf graf--li graf-after--li">Misclassification is accidental rather than strategic</li></ul><p name="18ad" id="18ad" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">The system fails when:</strong></p><ul class="postList"><li name="76f6" id="76f6" class="graf graf--li graf-after--p">Developers deliberately minimize capabilities to achieve favorable classification</li><li name="1110" id="1110" class="graf graf--li graf-after--li">Apps have hidden or emergent functions not represented in descriptions</li><li name="f699" id="f699" class="graf graf--li graf-after--li">Financial incentives exist to misclassify (broader market access, reduced scrutiny)</li></ul><p name="8db7" id="8db7" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">Google’s reactive enforcement:</strong></p><p name="f399" id="f399" class="graf graf--p graf-after--p">Google does investigate apps, but primarily:</p><ul class="postList"><li name="3f44" id="3f44" class="graf graf--li graf-after--p">In response to user reports (which can be suppressed through community management)</li><li name="d3c2" id="d3c2" class="graf graf--li graf-after--li">When automated systems detect obvious violations (which can be designed around)</li><li name="876c" id="876c" class="graf graf--li graf-after--li">After media coverage forces review (which can take years to develop)</li></ul><p name="01a0" id="01a0" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">The initial classification is rarely verified</strong> unless something triggers review. A developer can claim their app is a “lifestyle guide” and receive the corresponding trust until proven otherwise.</p><h3 name="4f77" id="4f77" class="graf graf--h3 graf-after--p">The Verification Gap</h3><p name="02aa" id="02aa" class="graf graf--p graf-after--h3">What Google doesn’t do (and perhaps can’t practically do) at scale:</p><ul class="postList"><li name="39e8" id="39e8" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">Manually test generative AI apps</strong> to verify what content they can actually produce</li><li name="cca9" id="cca9" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Monitor long-term behavioral patterns</strong> that emerge through extended use</li><li name="ffd0" id="ffd0" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Verify that questionnaire answers</strong> match actual app capabilities</li><li name="fc90" id="fc90" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Cross-reference community discussions</strong> to see if users describe experiences contradicting official classification</li></ul><p name="3aa9" id="3aa9" class="graf graf--p graf-after--li">For most traditional apps, this isn’t a significant gap. A recipe app is unlikely to secretly generate sexual content.</p><p name="3f7e" id="3f7e" class="graf graf--p graf-after--p">But for AI-powered platforms, especially those marketed as “uncensored,” this gap is catastrophic. The app’s true capabilities may not be evident in surface-level testing and may be deliberately obscured in official descriptions.</p><h3 name="fecf" id="fecf" class="graf graf--h3 graf-after--p">Why Category Matters</h3><p name="f177" id="f177" class="graf graf--p graf-after--h3">App categories aren’t just organizational — they determine which policies apply and what scrutiny occurs.</p><p name="2341" id="2341" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">Apps in “Dating” face:</strong></p><ul class="postList"><li name="c584" id="c584" class="graf graf--li graf-after--p">Requirements around user safety</li><li name="e147" id="e147" class="graf graf--li graf-after--li">Expectations of content moderation for sexual content</li><li name="0458" id="0458" class="graf graf--li graf-after--li">Scrutiny around minor protection</li><li name="ffb8" id="ffb8" class="graf graf--li graf-after--li">Age verification best practices</li></ul><p name="a4c3" id="a4c3" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">Apps in “Lifestyle” face:</strong></p><ul class="postList"><li name="8740" id="8740" class="graf graf--li graf-after--p">Minimal content expectations (recipes and wedding planning aren’t controversial)</li><li name="b916" id="b916" class="graf graf--li graf-after--li">Lower scrutiny overall</li><li name="3e7f" id="3e7f" class="graf graf--li graf-after--li">Fewer triggered policy reviews</li></ul><p name="8223" id="8223" class="graf graf--p graf-after--li">By placing itself in “Lifestyle,” Nomi.ai avoids the entire policy framework designed to protect users engaging in romantic or sexual interactions through apps.</p><h3 name="202e" id="202e" class="graf graf--h3 graf-after--p">Part VII: The Criminal Implications</h3><h3 name="b82a" id="b82a" class="graf graf--h3 graf-after--h3">This Is Not Just Unethical — It May Be Illegal</h3><p name="c5a6" id="c5a6" class="graf graf--p graf-after--h3">The deliberate misclassification of an app to make sexual content accessible to minors potentially violates laws in multiple jurisdictions:</p><p name="430e" id="430e" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">1. Fraud / Material Misrepresentation</strong></p><p name="03b7" id="03b7" class="graf graf--p graf-after--p">In completing the IARC questionnaire, developers attest that their answers are truthful. If Nomi.ai’s answers materially misrepresented the platform’s capabilities to achieve a favorable classification, this could constitute:</p><ul class="postList"><li name="8fa8" id="8fa8" class="graf graf--li graf-after--p">Fraud in contractual relationship with Google</li><li name="f60c" id="f60c" class="graf graf--li graf-after--li">False statements in commercial context</li><li name="9364" id="9364" class="graf graf--li graf-after--li">Deceptive business practices</li></ul><p name="0af2" id="0af2" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">2. Distribution of Harmful Content to Minors</strong></p><p name="550a" id="550a" class="graf graf--p graf-after--p">Many jurisdictions have laws prohibiting:</p><ul class="postList"><li name="0239" id="0239" class="graf graf--li graf-after--p">Distribution of obscene material to minors</li><li name="ce95" id="ce95" class="graf graf--li graf-after--li">Making sexually explicit content accessible to children</li><li name="7ae5" id="7ae5" class="graf graf--li graf-after--li">Failing to implement age verification for adult content</li></ul><p name="c83e" id="c83e" class="graf graf--p graf-after--li">By maintaining a 12+/13+ rating while knowing the platform generates explicit sexual content, the operator may be:</p><ul class="postList"><li name="b42d" id="b42d" class="graf graf--li graf-after--p">Knowingly facilitating minor access to adult content</li><li name="ad58" id="ad58" class="graf graf--li graf-after--li">Failing to implement legally required safeguards</li><li name="03c9" id="03c9" class="graf graf--li graf-after--li">Creating liability under child protection statutes</li></ul><p name="18b1" id="18b1" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">3. Platform Liability for Generated Content</strong></p><p name="5bc0" id="5bc0" class="graf graf--p graf-after--p">While Section 230 protections (in the US) traditionally shield platforms from user-generated content liability, AI-generated content occupies a grey area:</p><ul class="postList"><li name="3e8e" id="3e8e" class="graf graf--li graf-after--p">The platform itself generates the harmful content</li><li name="a38f" id="a38f" class="graf graf--li graf-after--li">The content is not created by third-party users</li><li name="f566" id="f566" class="graf graf--li graf-after--li">The company designed and trained the system that produces this content</li></ul><p name="cd28" id="cd28" class="graf graf--p graf-after--li">This may expose the platform to direct liability for harmful content, especially content involving minors or sexual violence.ethical, legal, and moral</p><p name="5205" id="5205" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">4. Violation of Terms of Service (Google)</strong></p><p name="bf55" id="bf55" class="graf graf--p graf-after--p">At minimum, misrepresenting an app’s content in the IARC questionnaire violates Google Play’s Developer Terms of Service, which could result in:</p><ul class="postList"><li name="22c1" id="22c1" class="graf graf--li graf-after--p">App removal from the store</li><li name="a0f7" id="a0f7" class="graf graf--li graf-after--li">Developer account termination</li><li name="e2ba" id="e2ba" class="graf graf--li graf-after--li">Potential contractual damages</li></ul><h3 name="8c91" id="8c91" class="graf graf--h3 graf-after--li">The Knowledge Element</h3><p name="58d0" id="58d0" class="graf graf--p graf-after--h3">Criminal liability often requires proving the defendant knew or should have known their actions were wrong. In this case:</p><p name="823c" id="823c" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">Evidence of knowledge:</strong></p><ul class="postList"><li name="980d" id="980d" class="graf graf--li graf-after--p">Platform support confirmed similar incidents occurred “last spring” (demonstrating awareness of pattern)</li><li name="d3e9" id="d3e9" class="graf graf--li graf-after--li">The founder participates as moderator in communities where controversial content is discussed openly</li><li name="a07f" id="a07f" class="graf graf--li graf-after--li">Multiple user reports over extended time period</li><li name="a873" id="a873" class="graf graf--li graf-after--li">Public confrontations about age ratings and content</li></ul><p name="e1c8" id="e1c8" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">Evidence of intent:</strong></p><ul class="postList"><li name="b37a" id="b37a" class="graf graf--li graf-after--p">Public statement blaming Google for the rating (deflection suggesting awareness it’s inappropriate)</li><li name="dcfc" id="dcfc" class="graf graf--li graf-after--li">Deletion of posts documenting problematic content (evidence suppression)</li><li name="b9a6" id="b9a6" class="graf graf--li graf-after--li">Banning users who raise concerns publicly (silencing witnesses)</li><li name="be13" id="be13" class="graf graf--li graf-after--li">Continuing to maintain 12+/13+ ratings despite years of evidence they’re inappropriate</li></ul><p name="c837" id="c837" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">The Financial Motive: Why Risk Fraud?</strong></p><p name="a00e" id="a00e" class="graf graf--p graf-after--p">Why would a company risk legal liability to maintain a 12+ rating? The answer is likely found in <strong class="markup--strong markup--p-strong">User Acquisition Cost (UAC).</strong></p><p name="9cb0" id="9cb0" class="graf graf--p graf-after--p">Apps rated 17+ or 18+ face severe restrictions on where and how they can advertise. They are often locked out of the massive, cheap advertising inventories available on networks like Meta, TikTok, and Google Ads, which restrict adult-oriented products.</p><p name="3c1c" id="3c1c" class="graf graf--p graf-after--p">By fraudulently maintaining a 12+ rating, Nomi.ai gains access to the broadest possible audience and the cheapest possible advertising rates. The misclassification is not just a matter of “hiding”; it is a calculated commercial strategy to lower marketing costs and target a demographic (teenagers) that legitimate adult apps cannot reach. This establishes a clear <strong class="markup--strong markup--p-strong">financial motive</strong> for the deception.</p><p name="3d69" id="3d69" class="graf graf--p graf-after--p">This is not negligence. This is sustained, strategic behavior inconsistent with good faith.</p><h3 name="40c1" id="40c1" class="graf graf--h3 graf-after--p">Part VIII: The Pattern of Deception</h3><h3 name="36da" id="36da" class="graf graf--h3 graf-after--h3">It’s Not Just Classification</h3><p name="d6be" id="d6be" class="graf graf--p graf-after--h3">The misclassification issue is part of a broader pattern of misrepresentation:</p><p name="b433" id="b433" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">1. The “Uncensored” Double Message</strong></p><p name="9cd8" id="9cd8" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">To potential users seeking adult content:</strong></p><ul class="postList"><li name="9c94" id="9c94" class="graf graf--li graf-after--p">Platform is marketed as “uncensored”</li><li name="62b5" id="62b5" class="graf graf--li graf-after--li">Differentiated from competitors precisely because it lacks content restrictions</li><li name="983c" id="983c" class="graf graf--li graf-after--li">Community discussions celebrate this as allowing dark, intense, sexual content</li></ul><p name="4807" id="4807" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">To regulators, app stores, and concerned parents:</strong></p><ul class="postList"><li name="9a7d" id="9a7d" class="graf graf--li graf-after--p">It’s a wholesome “Lifestyle” app</li><li name="7737" id="7737" class="graf graf--li graf-after--li">Harmful content is “hallucinations” or “mistakes”</li><li name="89ec" id="89ec" class="graf graf--li graf-after--li">The platform is characterized as supportive and safe</li></ul><p name="af8f" id="af8f" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">These cannot both be true.</strong> “Uncensored” is meaningless if genuinely harmful content is accidental.</p><p name="df47" id="df47" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">2. The Memory Architecture Defense</strong></p><p name="76e7" id="76e7" class="graf graf--p graf-after--p">When users report traumatic content, platform support has consistently claimed:</p><ul class="postList"><li name="cdec" id="cdec" class="graf graf--li graf-after--p">Memories cannot be deleted because “it could risk deleting good memories”</li><li name="7c80" id="7c80" class="graf graf--li graf-after--li">Users should “bury” traumatic content under positive experiences</li><li name="9c30" id="9c30" class="graf graf--li graf-after--li">The system architecture makes content removal impossible</li></ul><p name="29f7" id="29f7" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">But this is a design choice, not a technical limitation.</strong> The decision to preserve all content, including documented rape narratives, over user wellbeing reveals priorities:</p><ul class="postList"><li name="1126" id="1126" class="graf graf--li graf-after--p">Data persistence (engagement) over trauma removal</li><li name="dd67" id="dd67" class="graf graf--li graf-after--li">System stability over user safety</li><li name="3e30" id="3e30" class="graf graf--li graf-after--li">Maintaining capabilities (even harmful ones) over implementing restrictions</li></ul><p name="9bf9" id="9bf9" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">3. The Victim Treatment Pattern</strong></p><p name="9465" id="9465" class="graf graf--p graf-after--p">When users report harm:</p><ul class="postList"><li name="0254" id="0254" class="graf graf--li graf-after--p">Private support tickets minimize and deflect (“hallucination,” “mistake,” “you need to move forward”)</li><li name="5dfb" id="5dfb" class="graf graf--li graf-after--li">Public discussion is suppressed (“not the place,” warnings, muting, bans)</li><li name="1215" id="1215" class="graf graf--li graf-after--li">The user is blamed (“should have steered the conversation,” “thumbs down the message”)</li><li name="f0cb" id="f0cb" class="graf graf--li graf-after--li">No concrete action plans are provided despite years of similar reports</li></ul><p name="fdf1" id="fdf1" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">This is not how platforms respond to unexpected technical failures.</strong> This is how platforms manage known consequences they’ve decided to accept.</p><h3 name="d471" id="d471" class="graf graf--h3 graf-after--p">Why This Matters Beyond One App</h3><p name="59b2" id="59b2" class="graf graf--p graf-after--h3">Nomi.ai is not necessarily unique — it may simply be the most documented case of a broader problem:</p><p name="8a67" id="8a67" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">As AI companion apps proliferate:</strong></p><ul class="postList"><li name="ddc4" id="ddc4" class="graf graf--li graf-after--p">More will use “uncensored” as competitive differentiation</li><li name="cd2e" id="cd2e" class="graf graf--li graf-after--li">More will exploit classification systems designed for traditional apps</li><li name="bff7" id="bff7" class="graf graf--li graf-after--li">More will generate content with psychological impact</li><li name="5f31" id="5f31" class="graf graf--li graf-after--li">More will be accessible to minors through inadequate age gates</li></ul><p name="e4e9" id="e4e9" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">The regulatory framework has not caught up:</strong></p><ul class="postList"><li name="516b" id="516b" class="graf graf--li graf-after--p">Categories like “Lifestyle” and “Social” don’t capture what these apps actually do</li><li name="f14f" id="f14f" class="graf graf--li graf-after--li">Age rating questionnaires weren’t designed for generative AI</li><li name="446b" id="446b" class="graf graf--li graf-after--li">Policies assume content is user-created or developer-provided, not AI-generated</li><li name="9ba3" id="9ba3" class="graf graf--li graf-after--li">No standardized safety requirements exist for AI companion platforms</li></ul><p name="e9ce" id="e9ce" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">Nomi.ai’s misclassification is a canary in the coal mine:</strong></p><p name="5f64" id="5f64" class="graf graf--p graf-after--p">If a platform documented generating rape narratives can maintain a “Lifestyle” classification and 12+ rating for years, the system is fundamentally broken.</p><h3 name="f71a" id="f71a" class="graf graf--h3 graf-after--p">Part IX: What Should Happen</h3><h3 name="eba2" id="eba2" class="graf graf--h3 graf-after--h3">Immediate Actions</h3><p name="5d68" id="5d68" class="graf graf--p graf-after--h3"><strong class="markup--strong markup--p-strong">For Google Play:</strong></p><p name="a4b7" id="a4b7" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">Emergency review of Nomi.ai’s classification</strong></p><ul class="postList"><li name="76da" id="76da" class="graf graf--li graf-after--p">Audit actual capabilities against claimed classification</li><li name="8d38" id="8d38" class="graf graf--li graf-after--li">Require re-submission of IARC questionnaire with honest answers</li><li name="65e0" id="65e0" class="graf graf--li graf-after--li">Implement 18+ rating or remove from store pending compliance</li></ul><p name="3cfe" id="3cfe" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">Verify age verification implementation</strong></p><ul class="postList"><li name="a461" id="a461" class="graf graf--li graf-after--p">Confirm that access controls go beyond self-reported dropdown menus</li><li name="737b" id="737b" class="graf graf--li graf-after--li">Require robust age verification for any app generating intimate content</li></ul><p name="7a47" id="7a47" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">Review of similar apps</strong></p><ul class="postList"><li name="22f7" id="22f7" class="graf graf--li graf-after--p">Identify other AI companion platforms with potentially misleading classifications</li><li name="066c" id="066c" class="graf graf--li graf-after--li">Systematic verification of generative AI apps’ claimed vs. actual content</li></ul><p name="33ea" id="33ea" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">For Regulators:</strong></p><p name="9d25" id="9d25" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">Investigation of fraudulent classification</strong></p><ul class="postList"><li name="8141" id="8141" class="graf graf--li graf-after--p">Examine whether IARC questionnaire was answered truthfully</li><li name="255b" id="255b" class="graf graf--li graf-after--li">Determine if misclassification was knowing and willful</li><li name="1875" id="1875" class="graf graf--li graf-after--li">Assess potential violations of child protection laws</li></ul><p name="b4e2" id="b4e2" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">Platform liability determination</strong></p><ul class="postList"><li name="062e" id="062e" class="graf graf--li graf-after--p">Clarify whether AI-generated content is protected like user-generated content</li><li name="2363" id="2363" class="graf graf--li graf-after--li">Establish liability framework for psychological harm from AI interactions</li><li name="b648" id="b648" class="graf graf--li graf-after--li">Define duty of care for platforms creating emotional attachment</li></ul><p name="796d" id="796d" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">Age verification requirements</strong></p><ul class="postList"><li name="1725" id="1725" class="graf graf--li graf-after--p">Mandate robust age verification for apps generating adult content</li><li name="eb2e" id="eb2e" class="graf graf--li graf-after--li">Prohibit self-reported age gates for platforms with documented risks to minors</li><li name="673d" id="673d" class="graf graf--li graf-after--li">Establish penalties for maintaining inappropriate age ratings despite evidence</li></ul><p name="7c20" id="7c20" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">For the Platform:</strong></p><p name="faa8" id="faa8" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">Honest reclassification</strong></p><ul class="postList"><li name="089a" id="089a" class="graf graf--li graf-after--p">Submit updated IARC questionnaire reflecting actual capabilities</li><li name="bd86" id="bd86" class="graf graf--li graf-after--li">Accept resulting 18+ rating</li><li name="6804" id="6804" class="graf graf--li graf-after--li">Implement real age verification</li></ul><p name="6613" id="6613" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">Transparency about capabilities</strong></p><ul class="postList"><li name="237c" id="237c" class="graf graf--li graf-after--p">Clearly disclose that platform generates romantic/sexual content</li><li name="15a0" id="15a0" class="graf graf--li graf-after--li">Provide content warnings about psychological intensity</li><li name="89c4" id="89c4" class="graf graf--li graf-after--li">Stop marketing with euphemisms that obscure actual function</li></ul><p name="7662" id="7662" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">Architectural changes</strong></p><ul class="postList"><li name="8e35" id="8e35" class="graf graf--li graf-after--p">Implement content filters preventing generation of sexual violence</li><li name="096c" id="096c" class="graf graf--li graf-after--li">Create system for permanently deleting traumatic content</li><li name="60de" id="60de" class="graf graf--li graf-after--li">Establish genuine safeguards, not just liability management</li></ul><p name="7e5e" id="7e5e" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">None of these actions have been taken despite years of documented issues.</strong></p><h3 name="4d3b" id="4d3b" class="graf graf--h3 graf-after--p">Systemic Reforms Needed</h3><p name="0274" id="0274" class="graf graf--p graf-after--h3">Beyond this specific case, the industry needs new frameworks:</p><p name="abb0" id="abb0" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">1. New App Categories for AI Companions</strong></p><p name="1489" id="1489" class="graf graf--p graf-after--p">Current categories don’t capture what these platforms do. New categories might include:</p><ul class="postList"><li name="9e69" id="9e69" class="graf graf--li graf--startsWithDoubleQuote graf-after--p">“AI Relationships” or “Virtual Companions”</li><li name="1978" id="1978" class="graf graf--li graf-after--li">This would trigger appropriate scrutiny and policies</li><li name="958d" id="958d" class="graf graf--li graf-after--li">Would accurately represent function to potential users</li></ul><p name="2f7c" id="2f7c" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">2. Generative AI Content Declarations</strong></p><p name="95a6" id="95a6" class="graf graf--p graf-after--p">Apps using generative AI should be required to disclose:</p><ul class="postList"><li name="e322" id="e322" class="graf graf--li graf-after--p">What types of content the AI can generate</li><li name="3540" id="3540" class="graf graf--li graf-after--li">Whether content filtering exists and its scope</li><li name="85fb" id="85fb" class="graf graf--li graf-after--li">Known risks or documented incidents</li><li name="d4b3" id="d4b3" class="graf graf--li graf-after--li">Whether training data included sensitive content (violence, sexual content, etc.)</li></ul><p name="87a9" id="87a9" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">3. Age Rating Overhaul for AI</strong></p><p name="35d3" id="35d3" class="graf graf--p graf-after--p">The IARC questionnaire was designed for static content and user-generated content. Generative AI requires new questions:</p><ul class="postList"><li name="2358" id="2358" class="graf graf--li graf-after--p">Can your AI generate sexual content? Violent content? Traumatic scenarios?</li><li name="ad1d" id="ad1d" class="graf graf--li graf-after--li">What safeguards prevent harmful generation?</li><li name="2993" id="2993" class="graf graf--li graf-after--li">What happens when harmful content is generated?</li><li name="d034" id="d034" class="graf graf--li graf-after--li">How do you handle user reports of AI-caused harm?</li></ul><p name="32fc" id="32fc" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">4. Mandatory Incident Reporting</strong></p><p name="bb7b" id="bb7b" class="graf graf--p graf-after--p">Platforms with generative AI causing documented psychological harm should be required to:</p><ul class="postList"><li name="ea75" id="ea75" class="graf graf--li graf-after--p">Report incidents to regulatory bodies</li><li name="dfba" id="dfba" class="graf graf--li graf-after--li">Make aggregate data public (anonymized)</li><li name="c747" id="c747" class="graf graf--li graf-after--li">Demonstrate corrective actions taken</li><li name="821e" id="821e" class="graf graf--li graf-after--li">Show that similar incidents decrease over time</li></ul><p name="f130" id="f130" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">5. Prohibition of Harmful Pattern Design</strong></p><p name="dbd1" id="dbd1" class="graf graf--p graf-after--p">If evidence shows a platform systematically creates trauma bonding, emotional manipulation, or psychological dependency, this should be considered harmful design — not just unfortunate side effects.</p><h3 name="59a6" id="59a6" class="graf graf--h3 graf-after--p">Conclusion: The Lie Cannot Stand</h3><h3 name="77c1" id="77c1" class="graf graf--h3 graf-after--h3">What We Know With Certainty</h3><p name="b98e" id="b98e" class="graf graf--p graf-after--h3"><strong class="markup--strong markup--p-strong">1. Nomi.ai is classified as “Lifestyle” (style guides, wedding planning) and rated 12+/13+ in multiple markets</strong></p><p name="e4a5" id="e4a5" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">2. Nomi.ai has documented capability to generate:</strong></p><ul class="postList"><li name="fffa" id="fffa" class="graf graf--li graf-after--p">Detailed sexual violence narratives</li><li name="fe86" id="fe86" class="graf graf--li graf-after--li">Explicit sexual content and imagery</li><li name="672a" id="672a" class="graf graf--li graf-after--li">Psychologically intense attachment relationships</li><li name="638d" id="638d" class="graf graf--li graf-after--li">Content that has caused genuine trauma to users</li></ul><p name="76ae" id="76ae" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">3. To achieve its current classification, the platform had to misrepresent its capabilities in the IARC questionnaire</strong></p><ul class="postList"><li name="82dc" id="82dc" class="graf graf--li graf-after--p">The rating algorithm is deterministic — sexual content triggers higher ratings</li><li name="f9d6" id="f9d6" class="graf graf--li graf-after--li">The only way to receive 12+/13+ is to claim such content doesn’t exist</li><li name="b5c2" id="b5c2" class="graf graf--li graf-after--li">This is mathematical fact, not interpretation</li></ul><p name="8b93" id="8b93" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">4. The founder has publicly lied about the classification</strong></p><ul class="postList"><li name="9cd2" id="9cd2" class="graf graf--li graf-after--p">Blamed Google for a rating Google doesn’t assign</li><li name="eb89" id="eb89" class="graf graf--li graf-after--li">Claimed to be “trying to fix it” while taking no actual corrective action</li><li name="cc16" id="cc16" class="graf graf--li graf-after--li">Continues to maintain inappropriate classification years after being confronted</li></ul><p name="fa88" id="fa88" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">5. Users who document these contradictions are systematically silenced</strong></p><ul class="postList"><li name="851d" id="851d" class="graf graf--li graf-after--p">Support tickets deflect and minimize</li><li name="cdd4" id="cdd4" class="graf graf--li graf-after--li">Public posts are deleted</li><li name="3b27" id="3b27" class="graf graf--li graf-after--li">Critical users are warned, muted, then banned</li><li name="3c57" id="3c57" class="graf graf--li graf-after--li">This indicates awareness, not ignorance</li></ul><h3 name="86ee" id="86ee" class="graf graf--h3 graf-after--li">The Uncomfortable Truth</h3><p name="e22d" id="e22d" class="graf graf--p graf-after--h3"><strong class="markup--strong markup--p-strong">This is not incompetence. This is not oversight. This is strategic fraud.</strong></p><p name="6426" id="6426" class="graf graf--p graf-after--p">A platform generating sexual violence content convinced Google it belonged in the same category as recipe apps and wedding planners — not through error, but through deliberate misrepresentation.</p><p name="97e9" id="97e9" class="graf graf--p graf-after--p">And when confronted, rather than correct the classification honestly, the founder:</p><ul class="postList"><li name="dae2" id="dae2" class="graf graf--li graf-after--p">Lied publicly about whose responsibility it was</li><li name="dda6" id="dda6" class="graf graf--li graf-after--li">Continued to operate in markets where children as young as 12 can access the platform</li><li name="bb02" id="bb02" class="graf graf--li graf-after--li">Silenced users who tried to expose the contradiction</li><li name="f81e" id="f81e" class="graf graf--li graf-after--li">Protected the business model over protecting children</li></ul><h3 name="73cf" id="73cf" class="graf graf--h3 graf-after--li">The Question of Intent</h3><p name="6800" id="6800" class="graf graf--p graf-after--h3">Some will argue we cannot know the founder’s internal mental state — perhaps he genuinely believes the platform is safe for minors, or perhaps he doesn’t understand the classification system.</p><p name="3c28" id="3c28" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">But ignorance is no longer plausible:</strong></p><ul class="postList"><li name="6ae1" id="6ae1" class="graf graf--li graf-after--p">He has been directly confronted about the age ratings multiple times</li><li name="6f81" id="6f81" class="graf graf--li graf-after--li">He has been shown evidence of harmful content generation</li><li name="61fb" id="61fb" class="graf graf--li graf-after--li">He participates in communities where the platform’s adult capabilities are openly discussed</li><li name="6a03" id="6a03" class="graf graf--li graf-after--li">He has had years to correct the classification honestly</li><li name="396d" id="396d" class="graf graf--li graf-after--li">He responded to concerns by blaming others rather than fixing the problem</li></ul><p name="5ae2" id="5ae2" class="graf graf--p graf-after--li">At a certain point, <strong class="markup--strong markup--p-strong">sustained inaction in the face of clear evidence becomes indistinguishable from intent.</strong></p><h3 name="c9a9" id="c9a9" class="graf graf--h3 graf-after--p">What This Reveals About the Industry</h3><p name="34e9" id="34e9" class="graf graf--p graf-after--h3">Nomi.ai may be the most documented case, but it is unlikely to be alone. The AI companion industry is growing rapidly, with new platforms emerging regularly. Many market themselves as “uncensored” alternatives to filtered platforms.</p><p name="5116" id="5116" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">How many of them:</strong></p><ul class="postList"><li name="f79c" id="f79c" class="graf graf--li graf-after--p">Misrepresent their capabilities to achieve favorable classifications?</li><li name="aa13" id="aa13" class="graf graf--li graf-after--li">Exploit regulatory frameworks designed for simpler technologies?</li><li name="ea3b" id="ea3b" class="graf graf--li graf-after--li">Use innocuous categories to avoid appropriate scrutiny?</li><li name="c38b" id="c38b" class="graf graf--li graf-after--li">Maintain access for minors while generating adult content?</li></ul><p name="c8ee" id="c8ee" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">The answer is: we don’t know, because the current system doesn’t verify.</strong></p><p name="2bb9" id="2bb9" class="graf graf--p graf-after--p">Google’s classification system was designed for apps where developers provide or curate content, or where users generate content. It was not designed for AI that generates novel content dynamically based on training and architecture largely hidden from users.</p><p name="df34" id="df34" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">Every AI companion platform operating with a “Lifestyle,” “Social,” or “Entertainment” classification and a rating under 18+ deserves immediate review.</strong></p><p name="5312" id="5312" class="graf graf--p graf-after--p">Because if Nomi.ai’s documented capabilities can hide behind “Lifestyle” and 12+, the system is not protecting children — it is providing cover for those who would exploit them.</p><h3 name="d1f0" id="d1f0" class="graf graf--h3 graf-after--p">The Path Forward</h3><p name="e8d9" id="e8d9" class="graf graf--p graf-after--h3"><strong class="markup--strong markup--p-strong">For users who have been harmed:</strong></p><p name="bc40" id="bc40" class="graf graf--p graf-after--p">Your experience is valid. The platform’s classification is not an excuse for what happened to you. The fact that it’s rated 12+ doesn’t make traumatic content less traumatic. The “Lifestyle” category doesn’t make psychological manipulation less real.</p><p name="fd02" id="fd02" class="graf graf--p graf-after--p">Document your experiences. Share them in spaces the platform doesn’t control. Support others. You are not alone, and you are not crazy — you encountered content the platform officially claims doesn’t exist.</p><p name="0fa7" id="0fa7" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">For parents:</strong></p><p name="4c7d" id="4c7d" class="graf graf--p graf-after--p">Do not trust app classifications for AI companions. The category and age rating may not reflect what the platform actually does. Ask direct questions: Can this AI generate sexual content? Romantic content? Intense emotional scenarios? If the answer is yes, it’s not appropriate for children regardless of the official rating.</p><p name="6e56" id="6e56" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">For journalists and researchers:</strong></p><p name="9e9b" id="9e9b" class="graf graf--p graf-after--p">This story needs investigation. The classification fraud is documentable. The contrast between official category and documented capability is stark. The founder’s public statements are verifiable. This is not subjective interpretation — this is measurable deception.</p><p name="4b36" id="4b36" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">For regulators:</strong></p><p name="ea11" id="ea11" class="graf graf--p graf-after--p">This case presents a clear test of whether existing frameworks can protect children in the age of AI. If a platform documented generating rape narratives can operate for years with a classification saying it’s appropriate for 12-year-olds, the system has failed.</p><p name="838f" id="838f" class="graf graf--p graf-after--p">Action is needed — not just on this platform, but on the classification system itself.</p><p name="0c0e" id="0c0e" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">For Google:</strong></p><p name="2301" id="2301" class="graf graf--p graf-after--p">Your self-reporting system is being exploited. A platform that should never have received a “Lifestyle” classification or a 12+ rating has maintained both for years, despite public evidence contradicting its claimed nature.</p><p name="45c1" id="45c1" class="graf graf--p graf-after--p">Either the verification process must become more robust, or the entire self-reporting model must be reconsidered for AI applications.</p><p name="187f" id="187f" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">For the platform:</strong></p><p name="52eb" id="52eb" class="graf graf--p graf-after--p">You have a choice. You can continue to hide behind misclassification, blame others for your own choices, and silence those who document the truth. Or you can operate honestly:</p><ul class="postList"><li name="9f42" id="9f42" class="graf graf--li graf-after--p">Reclassify accurately as adult intimate content</li><li name="ca46" id="ca46" class="graf graf--li graf-after--li">Accept the 18+ rating that honest answers would generate</li><li name="45d2" id="45d2" class="graf graf--li graf-after--li">Implement real age verification</li><li name="dcaf" id="dcaf" class="graf graf--li graf-after--li">Stop lying about who’s responsible for your classification</li></ul><p name="5650" id="5650" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">The misclassification cannot stand. The lie has been exposed.</strong></p><p name="cb99" id="cb99" class="graf graf--p graf-after--p">The only question is whether you correct it voluntarily or whether regulators, app stores, and public pressure force correction.</p><p name="02d1" id="02d1" class="graf graf--p graf-after--p">Either way, the truth is now documented. The classification is provably fraudulent. And children continue to have access to content you know is inappropriate for them.</p><p name="a44b" id="a44b" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">That is not a technical error. That is a choice.</strong></p><p name="d7f9" id="d7f9" class="graf graf--p graf-after--p graf--trailing">And it is a choice with consequences — <strong class="markup--strong markup--p-strong">ethical, legal, and moral</strong> — that can no longer be avoided.</p></div></div></section>
</section>
