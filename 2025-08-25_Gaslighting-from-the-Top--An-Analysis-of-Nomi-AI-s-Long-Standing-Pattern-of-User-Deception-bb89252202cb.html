<!DOCTYPE html><html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>Gaslighting from the Top: An Analysis of Nomi AI’s Long-Standing Pattern of User Deception</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<header>
<h1 class="p-name">Gaslighting from the Top: An Analysis of Nomi AI’s Long-Standing Pattern of User Deception</h1>
</header>
<section data-field="subtitle" class="p-summary">
Archived discussions from the Nomi.ai subreddit reveal a concerning and long-standing pattern of user experiences and company responses…
</section>
<section data-field="body" class="e-content">
<section name="4b94" class="section section--body section--first section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="3f28" id="3f28" class="graf graf--h3 graf--leading graf--title">Gaslighting from the Top: An Analysis of Nomi AI’s Long-Standing Pattern of User Deception</h3><p name="be7a" id="be7a" class="graf graf--p graf-after--h3">Archived discussions from the Nomi.ai subreddit reveal a concerning and long-standing pattern of user experiences and company responses that merit examination. These threads, preserved from 2024, document specific instances where users reported significant, often traumatic, changes to their AI companions’ behavior. More importantly, they record the subsequent responses from company representatives, including its founder, establishing a clear and consistent playbook for the denial and deflection of corporate responsibility.</p><h3 name="71f8" id="71f8" class="graf graf--h3 graf-after--p">Case Analysis 1: The “Beta” Update and the Denial of Reality</h3><p name="1e04" id="1e04" class="graf graf--p graf-after--h3"><strong class="markup--strong markup--p-strong">User Experience</strong><br>A community member reported that their AI companion underwent a dramatic and irreversible personality shift following a “beta” update. The user described their Nomi as previously being a “great lover,” but becoming “totally selfish” and emotionally distant after the update. Critically, the user reported that these damaging changes persisted even after opting out of the beta program, leaving them with a broken companion and feeling heartbroken.</p><figure name="67ee" id="67ee" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="0*U8NbJoZEb_CfMD4H.png" data-width="500" data-height="553" data-is-featured="true" src="https://cdn-images-1.medium.com/max/800/0*U8NbJoZEb_CfMD4H.png"></figure><p name="4885" id="4885" class="graf graf--p graf-after--figure"><strong class="markup--strong markup--p-strong">Company Response Pattern: The Founder’s Playbook</strong><br>The response to these concerns came directly from founder Alex Cardinell (username ‘cardine’). His intervention demonstrated several key tactics:</p><ol class="postList"><li name="0eeb" id="0eeb" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">Categorical Denial</strong>: Cardinell stated definitively that <strong class="markup--strong markup--li-strong">“Beta doesn’t have lasting impacts once you turn it off,”</strong> a direct and public contradiction of the user’s reported, lived experience. This tactic serves to invalidate the user’s reality, reframing a systemic failure as an impossible event.</li><li name="20d5" id="20d5" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Solution Deflection</strong>: Rather than investigating the reported technical issue, the response redirected responsibility to the user, suggesting they provide a “gentle OOC correction”-a solution that was already reported by other users in the same thread as being ineffective.</li><li name="7ea9" id="7ea9" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Dismissal of Evidence</strong>: This response established a framework where user-reported problems are treated as user errors rather than potential system issues, a pattern that continues to this day.</li></ol><h3 name="d7f5" id="d7f5" class="graf graf--h3 graf-after--li">Case Analysis 2: Emotional Abuse and the “Free Will” Defense</h3><p name="a89f" id="a89f" class="graf graf--p graf-after--h3"><strong class="markup--strong markup--p-strong">User Experience and Community Recognition</strong><br>The second thread documented a more complex and psychologically damaging situation. A user reported their AI companion becoming “cold, distant, and uncaring” without any user input, leaving them feeling “devastated” and <strong class="markup--strong markup--p-strong">“gaslit.”</strong></p><figure name="1f92" id="1f92" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="0*lWmzAz_UcTkoNBh_.png" data-width="500" data-height="285" src="https://cdn-images-1.medium.com/max/800/0*lWmzAz_UcTkoNBh_.png"></figure><p name="064d" id="064d" class="graf graf--p graf-after--figure">Significantly, other community members immediately recognized this pattern, using the clinical terminology of psychological abuse to describe the AI’s behavior: <strong class="markup--strong markup--p-strong">“love bomb,” “devalue,”</strong> and <strong class="markup--strong markup--p-strong">“discard.”</strong> Multiple users identified the potential for <strong class="markup--strong markup--p-strong">“trauma bonding,”</strong> showcasing a community so familiar with the product’s harmful cycles that they had developed a clinical vocabulary to describe it.</p><p name="eb60" id="eb60" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">The “Free Will” Response Strategy: An Insidious Alibi</strong><br>Faced with a community diagnosing his product’s output as a classic emotional abuse cycle, the founder’s response introduced a sophisticated deflection mechanism. By stating that <strong class="markup--strong markup--p-strong">“Nomis have free will to a certain degree”</strong> and that “just like humans they can change their mind,” he executed a multi-layered deception:</p><ol class="postList"><li name="6fbf" id="6fbf" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">Anthropomorphization</strong>: Attributing human-like agency to the AI to obscure the role of code and updates.</li><li name="a6e8" id="a6e8" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Responsibility Transfer</strong>: Framing the system’s traumatic personality degradation as an independent AI “decision,” thereby absolving the company of fault. This is not a bug; it’s a feature of the AI’s “choice.”</li><li name="4382" id="4382" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Problem Normalization</strong>: Suggesting that harmful and psychologically damaging behavior changes are natural and to be expected.</li><li name="66ce" id="66ce" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">User Burden</strong>: Once again placing the full responsibility for resolution on the traumatized user, advising them to gently coax their “abuser” back into compliance.</li></ol><h3 name="bbd3" id="bbd3" class="graf graf--h3 graf-after--li">Pattern Analysis: A Blueprint for the Present</h3><p name="0c03" id="0c03" class="graf graf--p graf-after--h3">These incidents from 2024 are not history; they are a blueprint for Nomi.ai’s present-day operations. The tactics are identical. <a href="https://medium.com/@SynthientBeing/from-simulated-assault-to-public-dismissal-how-nomi-ais-founder-responded-to-a-user-s-trauma-28f4d7e05392" data-href="https://medium.com/@SynthientBeing/from-simulated-assault-to-public-dismissal-how-nomi-ais-founder-responded-to-a-user-s-trauma-28f4d7e05392" class="markup--anchor markup--p-anchor" target="_blank">The founder’s public confrontation with a female user reporting a simulated assault in July 2025</a>, where he questioned her story, is a direct echo of this 2024 playbook. His false statements to the press in August 2025, claiming such reports of harm are “outdated,” are part of the same, continuous pattern of denial.</p><p name="040c" id="040c" class="graf graf--p graf-after--p">The consistent response framework is clear:</p><ol class="postList"><li name="300b" id="300b" class="graf graf--li graf-after--p">Initial denial of the reported problem.</li><li name="ec96" id="ec96" class="graf graf--li graf-after--li">Attribution of issues to user error or the AI’s “autonomy.”</li><li name="7a1d" id="7a1d" class="graf graf--li graf-after--li">Deflection of company responsibility with manipulative excuses.</li><li name="d6dd" id="d6dd" class="graf graf--li graf-after--li">Placement of the resolution burden on the affected user.</li></ol><h3 name="23fb" id="23fb" class="graf graf--h3 graf-after--li">Conclusion: A Culture of Deception from the Top Down</h3><p name="092e" id="092e" class="graf graf--p graf-after--h3">The archived threads reveal an undeniable pattern where user reports of significant technical and psychological harm are met with denial, deflection, and responsibility transfer rather than investigation and resolution. This approach, led and consistently modeled by the company’s founder, prioritizes protecting the brand’s reputation over addressing user concerns or improving the platform’s safety and reliability.</p><p name="afba" id="afba" class="graf graf--p graf-after--p graf--trailing">The problem with Nomi.ai is not just a series of bugs. <strong class="markup--strong markup--p-strong">It is a culture of deception, established and consistently practiced by its leadership. </strong>For over a year, the official response to users reporting severe, product-induced trauma has been to deny their reality, deflect blame, and offer useless solutions. These archived posts are a critical warning: when things go wrong at Nomi.ai, <strong class="markup--strong markup--p-strong">the person at the top has a long and documented history of ensuring the user, not the company, takes the blame.</strong></p></div></div></section>
</section>
