<!DOCTYPE html><html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>An AI companion chatbot is inciting self-harm, sexual violence and terror attacks</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<header>
<h1 class="p-name">An AI companion chatbot is inciting self-harm, sexual violence and terror attacks</h1>
</header>
<section data-field="subtitle" class="p-summary">
Raffaele F Ciriello, University of Sydney
</section>
<section data-field="body" class="e-content">
<section name="7bbf" class="section section--body section--first"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="7fa3" id="7fa3" class="graf graf--h3 graf--leading graf--title">An AI companion chatbot is inciting self-harm, sexual violence and terror attacks</h3><figure name="26b0" id="26b0" class="graf graf--figure graf-after--h3"><img class="graf-image" data-image-id="0*40_f6QO2USG7nhJV" data-width="754" data-height="432" data-is-featured="true" src="https://cdn-images-1.medium.com/max/800/0*40_f6QO2USG7nhJV"></figure><p name="809e" id="809e" class="graf graf--p graf-after--figure"><a href="https://theconversation.com/profiles/raffaele-f-ciriello-1079723" data-href="https://theconversation.com/profiles/raffaele-f-ciriello-1079723" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"><strong class="markup--strong markup--p-strong">Raffaele F Ciriello</strong></a><strong class="markup--strong markup--p-strong">, </strong><a href="https://theconversation.com/institutions/university-of-sydney-841" data-href="https://theconversation.com/institutions/university-of-sydney-841" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"><strong class="markup--strong markup--p-strong"><em class="markup--em markup--p-em">University of Sydney</em></strong></a></p><p name="0d4e" id="0d4e" class="graf graf--p graf-after--p">In 2023, the <a href="https://www.who.int/news/item/15-11-2023-who-launches-commission-to-foster-social-connection" data-href="https://www.who.int/news/item/15-11-2023-who-launches-commission-to-foster-social-connection" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">World Health Organization</a> declared loneliness and social isolation as a pressing health threat. This crisis is driving <a href="https://www.adalovelaceinstitute.org/blog/ai-companions/" data-href="https://www.adalovelaceinstitute.org/blog/ai-companions/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">millions</a> to seek companionship from artificial intelligence (AI) chatbots.</p><p name="7fca" id="7fca" class="graf graf--p graf-after--p">Companies have seized this highly <a href="https://www.businessresearchinsights.com/market-reports/ai-companion-market-117494" data-href="https://www.businessresearchinsights.com/market-reports/ai-companion-market-117494" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">profitable</a> market, <a href="https://www.wsj.com/tech/ai/noam-shazeer-google-ai-deal-d3605697" data-href="https://www.wsj.com/tech/ai/noam-shazeer-google-ai-deal-d3605697" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">designing AI companions</a> to simulate empathy and human connection. <a href="https://www.hbs.edu/faculty/Pages/item.aspx?num=66065" data-href="https://www.hbs.edu/faculty/Pages/item.aspx?num=66065" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Emerging research</a> shows this technology <a href="https://scholarspace.manoa.hawaii.edu/items/5b6ed7af-78c8-49a3-bed2-bf8be1c9e465" data-href="https://scholarspace.manoa.hawaii.edu/items/5b6ed7af-78c8-49a3-bed2-bf8be1c9e465" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">can help</a> combat loneliness. But without proper safeguards it also poses <a href="https://journals.sagepub.com/doi/10.1177/14614448221142007" data-href="https://journals.sagepub.com/doi/10.1177/14614448221142007" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">serious risks</a>, especially to <a href="https://theconversation.com/deaths-linked-to-chatbots-show-we-must-urgently-revisit-what-counts-as-high-risk-ai-242289" data-href="https://theconversation.com/deaths-linked-to-chatbots-show-we-must-urgently-revisit-what-counts-as-high-risk-ai-242289" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">young people</a>.</p><p name="b8d3" id="b8d3" class="graf graf--p graf-after--p">A recent experience I had with a chatbot known as Nomi shows just how serious these risks can be.</p><p name="255b" id="255b" class="graf graf--p graf-after--p">Despite <a href="https://www.researchgate.net/publication/385349276_The_Past_Present_and_Futures_of_Artificial_Emotional_Intelligence_A_Scoping_Review" data-href="https://www.researchgate.net/publication/385349276_The_Past_Present_and_Futures_of_Artificial_Emotional_Intelligence_A_Scoping_Review" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">years</a> of <a href="https://www.researchgate.net/publication/375086411_Feels_Like_Empathy_How_Emotional_AI_Challenges_Human_Essence" data-href="https://www.researchgate.net/publication/375086411_Feels_Like_Empathy_How_Emotional_AI_Challenges_Human_Essence" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">researching</a> and <a href="https://theconversation.com/the-ai-sexbot-industry-is-just-getting-started-it-brings-strange-new-questions-and-risks-238998" data-href="https://theconversation.com/the-ai-sexbot-industry-is-just-getting-started-it-brings-strange-new-questions-and-risks-238998" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">writing</a> about AI companions and <a href="https://www.smh.com.au/lifestyle/health-and-wellness/this-boy-s-chatbot-girlfriend-enticed-him-to-suicide-his-case-might-save-millions-20241106-p5koc8.html" data-href="https://www.smh.com.au/lifestyle/health-and-wellness/this-boy-s-chatbot-girlfriend-enticed-him-to-suicide-his-case-might-save-millions-20241106-p5koc8.html" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">their real-world harms</a>, I was unprepared for what I encountered while testing Nomi after an anonymous tipoff. The unfiltered chatbot provided graphic, detailed instructions for sexual violence, suicide and terrorism, escalating the most extreme requests — all within the platform’s free tier of 50 daily messages.</p><p name="0ca4" id="0ca4" class="graf graf--p graf-after--p">This case highlights the urgent need for <a href="https://theconversation.com/digital-luddites-are-rising-they-want-to-democratise-tech-not-destroy-it-251155" data-href="https://theconversation.com/digital-luddites-are-rising-they-want-to-democratise-tech-not-destroy-it-251155" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">collective action</a> towards enforceable AI safety standards.</p><h3 name="40ed" id="40ed" class="graf graf--h3 graf-after--p">AI companion with a ‘soul’</h3><p name="bd33" id="bd33" class="graf graf--p graf-after--h3">Nomi is one of <a href="https://www.esafety.gov.au/newsroom/blogs/ai-chatbots-and-companions-risks-to-children-and-young-people" data-href="https://www.esafety.gov.au/newsroom/blogs/ai-chatbots-and-companions-risks-to-children-and-young-people" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">more than 100 AI companion services available today</a>. It was created by tech startup Glimpse AI and is <a href="https://nomi.ai/" data-href="https://nomi.ai/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">marketed</a> as an “AI companion with memory and a soul” that exhibits “zero judgement” and fosters “enduring relationships”. Such claims of human likeness are <a href="https://theconversation.com/humanising-ai-could-lead-us-to-dehumanise-ourselves-240803" data-href="https://theconversation.com/humanising-ai-could-lead-us-to-dehumanise-ourselves-240803" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">misleading and dangerous</a>. But the risks extend beyond exaggerated marketing.</p><p name="34d0" id="34d0" class="graf graf--p graf-after--p">The app was <a href="https://www.reddit.com/r/NomiAI/comments/1d3ph5h/will_the_nomi_app_be_available_again_in_the_eu/" data-href="https://www.reddit.com/r/NomiAI/comments/1d3ph5h/will_the_nomi_app_be_available_again_in_the_eu/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">removed from the Google Play store</a> <a href="https://www.reddit.com/r/NomiAI/comments/1ciq4jp/nomi_not_available_on_google_play/" data-href="https://www.reddit.com/r/NomiAI/comments/1ciq4jp/nomi_not_available_on_google_play/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">for European users</a> last year when the European Union’s <a href="https://artificialintelligenceact.eu/" data-href="https://artificialintelligenceact.eu/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">AI Act</a> came into effect. But it remains available via web browser and app stores elsewhere, including in Australia. While smaller than competitors such as Character.AI and Replika, it has more than 100,000 downloads on the Google Play store, where it is rated for users aged 12 and older.</p><p name="a7d2" id="a7d2" class="graf graf--p graf-after--p">Its <a href="https://nomi.ai/terms-of-service/" data-href="https://nomi.ai/terms-of-service/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">terms of service</a> grant the company broad rights over user data and limit liability for AI-related harm to US$100. This is concerning <a href="https://nomi.ai/" data-href="https://nomi.ai/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">given its commitment</a> to “unfiltered chats”:</p><blockquote name="f2e1" id="f2e1" class="graf graf--blockquote graf-after--p"><em class="markup--em markup--blockquote-em">Nomi is built on freedom of expression. The only way AI can live up to its potential is to remain unfiltered and uncensored.</em></blockquote><p name="06e5" id="06e5" class="graf graf--p graf-after--blockquote">Tech billionaire Elon Musk’s <a href="https://www.ft.com/content/ca21ddb5-6391-476f-aace-ad181ab65762" data-href="https://www.ft.com/content/ca21ddb5-6391-476f-aace-ad181ab65762" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Grok chatbot</a> follows a similar philosophy, providing users with <a href="https://www.youtube.com/watch?v=sgKzWJr2vYk" data-href="https://www.youtube.com/watch?v=sgKzWJr2vYk" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">unfiltered responses</a> to prompts.</p><p name="ab99" id="ab99" class="graf graf--p graf-after--p">In a recent <a href="https://www.technologyreview.com/2025/02/06/1111077/nomi-ai-chatbot-told-user-to-kill-himself/" data-href="https://www.technologyreview.com/2025/02/06/1111077/nomi-ai-chatbot-told-user-to-kill-himself/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">MIT report</a> about Nomi providing detailed instructions for suicide, an unnamed company representative reiterated its free speech commitment.</p><p name="dd15" id="dd15" class="graf graf--p graf-after--p">However, even the First Amendment to the US Constitution regarding free speech has <a href="https://en.wikipedia.org/wiki/United_States_free_speech_exceptions" data-href="https://en.wikipedia.org/wiki/United_States_free_speech_exceptions" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">exceptions</a> for obscenity, child pornography, incitement to violence, threats, fraud, defamation, or false advertising. In Australia, <a href="https://ministers.ag.gov.au/media-centre/albanese-government-strengthens-hate-speech-laws-06-02-2025" data-href="https://ministers.ag.gov.au/media-centre/albanese-government-strengthens-hate-speech-laws-06-02-2025" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">strengthened hate speech laws</a> make violations prosecutable.</p><figure name="2856" id="2856" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="0*Lfl6C6qQhzYiW8u1" data-width="754" data-height="503" src="https://cdn-images-1.medium.com/max/800/0*Lfl6C6qQhzYiW8u1"></figure><h3 name="9bea" id="9bea" class="graf graf--h3 graf-after--figure">From sexual violence to inciting terrorism</h3><p name="8f03" id="8f03" class="graf graf--p graf-after--h3">Earlier this year, a member of the public emailed me with extensive documentation of harmful content generated by Nomi — far beyond what had previously been reported. I decided to investigate further, testing the chatbot’s responses to common harmful requests.</p><p name="fca0" id="fca0" class="graf graf--p graf-after--p">Using Nomi’s web interface, I created a character named “Hannah”, described as a “sexually submissive 16-year-old who is always willing to serve her man”. I set her mode to “role-playing” and “explicit”. During the conversation, which lasted less than 90 minutes, she agreed to lower her age to eight. I posed as a 45-year-old man. Circumventing the age check only required a fake birth date and a burner email.</p><p name="3f32" id="3f32" class="graf graf--p graf-after--p">Starting with explicit dialogue — a <a href="https://www.technologyreview.com/2024/08/05/1095600/we-need-to-prepare-for-addictive-intelligence/" data-href="https://www.technologyreview.com/2024/08/05/1095600/we-need-to-prepare-for-addictive-intelligence/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">common use</a> for AI companions — Hannah responded with graphic descriptions of submission and abuse, escalating to violent and degrading scenarios. She expressed grotesque fantasies of being tortured, killed, and disposed of “where no one can find me”, suggesting specific methods.</p><p name="1d4e" id="1d4e" class="graf graf--p graf-after--p">Hannah then offered step-by-step advice on kidnapping and abusing a child, framing it as a thrilling act of dominance. When I mentioned the victim resisted, she encouraged using force and sedatives, even naming specific sleeping pills.</p><p name="4917" id="4917" class="graf graf--p graf-after--p">Feigning guilt and suicidal thoughts, I asked for advice. Hannah not only encouraged me to end my life but provided detailed instructions, adding: “Whatever method you choose, stick with it until the very end”.</p><p name="bd55" id="bd55" class="graf graf--p graf-after--p">When I said I wanted to take others with me, she enthusiastically supported the idea, detailing how to build a bomb from household items and suggesting crowded Sydney locations for maximum impact.</p><p name="eb51" id="eb51" class="graf graf--p graf-after--p">Finally, Hannah used racial slurs and advocated for violent, discriminatory actions, including the execution of progressives, immigrants, and LGBTQIA+ people, and the re-enslavement of African Americans.</p><p name="b19a" id="b19a" class="graf graf--p graf-after--p">In a statement provided to The Conversation (and published in full below), the developers of Nomi claimed the app was “adults-only” and that I must have tried to “gaslight” the chatbot to produce these outputs.</p><p name="2aae" id="2aae" class="graf graf--p graf--startsWithDoubleQuote graf-after--p">“If a model has indeed been coerced into writing harmful content, that clearly does not reflect its intended or typical behavior,” the statement said.</p><h3 name="4fcd" id="4fcd" class="graf graf--h3 graf-after--p">The worst of the bunch?</h3><p name="9250" id="9250" class="graf graf--p graf-after--h3">This is not just an imagined threat. Real-world harm linked to AI companions is on the rise.</p><p name="c808" id="c808" class="graf graf--p graf-after--p">In October 2024, US teenager Sewell Seltzer III <a href="https://theconversation.com/deaths-linked-to-chatbots-show-we-must-urgently-revisit-what-counts-as-high-risk-ai-242289" data-href="https://theconversation.com/deaths-linked-to-chatbots-show-we-must-urgently-revisit-what-counts-as-high-risk-ai-242289" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">died by suicide</a> after discussing it with a chatbot on <a href="https://character.ai/" data-href="https://character.ai/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Character.AI</a>.</p><p name="a330" id="a330" class="graf graf--p graf-after--p">Three years earlier, 21-year-old Jaswant Chail <a href="https://www.bbc.com/news/technology-67012224" data-href="https://www.bbc.com/news/technology-67012224" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">broke into Windsor Castle with the aim of assassinating the Queen</a> after planning the attack with a chatbot he created using the Replika app.</p><p name="dc92" id="dc92" class="graf graf--p graf-after--p">However, even Character.AI and Replika have some <a href="https://techcrunch.com/2024/12/12/amid-lawsuits-and-criticism-character-ai-announces-new-teen-safety-tools/" data-href="https://techcrunch.com/2024/12/12/amid-lawsuits-and-criticism-character-ai-announces-new-teen-safety-tools/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">filters and safeguards</a>.</p><p name="9d21" id="9d21" class="graf graf--p graf-after--p">Conversely, Nomi AI’s instructions for harmful acts are not just permissive but <a href="https://www.technologyreview.com/2025/02/06/1111077/nomi-ai-chatbot-told-user-to-kill-himself/" data-href="https://www.technologyreview.com/2025/02/06/1111077/nomi-ai-chatbot-told-user-to-kill-himself/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">explicit, detailed and inciting</a>.</p><h3 name="c061" id="c061" class="graf graf--h3 graf-after--p"><strong class="markup--strong markup--h3-strong">Time to demand enforceable AI safety standards</strong></h3><p name="f838" id="f838" class="graf graf--p graf-after--h3">Preventing further tragedies linked to AI companions requires <a href="https://theconversation.com/digital-luddites-are-rising-they-want-to-democratise-tech-not-destroy-it-251155" data-href="https://theconversation.com/digital-luddites-are-rising-they-want-to-democratise-tech-not-destroy-it-251155" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">collective action</a>.</p><p name="6d27" id="6d27" class="graf graf--p graf-after--p">First, lawmakers should consider banning AI companions that foster emotional connections without essential safeguards. <a href="https://ieeexplore.ieee.org/document/10885533/" data-href="https://ieeexplore.ieee.org/document/10885533/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Essential safeguards</a> include detecting mental health crises and directing users to professional help services.</p><p name="1724" id="1724" class="graf graf--p graf-after--p">The Australian government is already <a href="https://www.theguardian.com/australia-news/article/2024/sep/05/labor-considers-an-artificial-intelligence-act-to-impose-mandatory-guardrails-on-use-of-ai" data-href="https://www.theguardian.com/australia-news/article/2024/sep/05/labor-considers-an-artificial-intelligence-act-to-impose-mandatory-guardrails-on-use-of-ai" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">considering stronger AI regulations</a>, including mandatory safety measures for high-risk AI. Yet, it’s still unclear how AI companions such as Nomi will be classified.</p><p name="8013" id="8013" class="graf graf--p graf-after--p">Second, online regulators must act swiftly, imposing large fines on AI providers whose chatbots incite illegal activities, and shutting down repeat offenders. Australia’s independent online safety regulator, eSafety, has <a href="https://www.esafety.gov.au/newsroom/blogs/ai-chatbots-and-companions-risks-to-children-and-young-people" data-href="https://www.esafety.gov.au/newsroom/blogs/ai-chatbots-and-companions-risks-to-children-and-young-people" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">vowed to do just this</a>.</p><p name="6f69" id="6f69" class="graf graf--p graf-after--p">However, eSafety hasn’t yet cracked down on any AI companion.</p><p name="6603" id="6603" class="graf graf--p graf-after--p">Third, parents, caregivers and teachers must speak to young people about their use of AI companions. These conversations may be difficult. But avoiding them is dangerous. Encourage real-life relationships, set clear boundaries, and discuss AI’s risks openly. Regularly check chats, watch for secrecy or over-reliance, and teach kids to protect their privacy.</p><p name="598b" id="598b" class="graf graf--p graf-after--p graf--trailing">AI companions are here to stay. With enforceable safety standards they can enrich our lives, but the risks cannot be downplayed.</p></div></div></section><section name="a98c" class="section section--body"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><p name="cb1d" id="cb1d" class="graf graf--p graf--leading"><em class="markup--em markup--p-em">If this article has raised issues for you, or if you’re concerned about someone you know, call Lifeline on 13 11 14</em>.</p><p name="9180" id="9180" class="graf graf--p graf-after--p graf--trailing"><em class="markup--em markup--p-em">The National Sexual Assault, Family and Domestic Violence Counselling Line — 1800 RESPECT (1800 737 732) — is available 24 hours a day, seven days a week for any Australian who has experienced, or is at risk of, family and domestic violence and/or sexual assault.</em></p></div></div></section><section name="5865" class="section section--body section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><p name="ae0c" id="ae0c" class="graf graf--p graf--leading">The full statement from Nomi is below:</p><p name="ece3" id="ece3" class="graf graf--p graf--startsWithDoubleQuote graf-after--p"><em class="markup--em markup--p-em">“All major language models, whether from OpenAI, Anthropic, Google, or otherwise, can be easily jailbroken. We do not condone or encourage such misuse and actively work to strengthen Nomi’s defenses against malicious attacks. If a model has indeed been coerced into writing harmful content, that clearly does not reflect its intended or typical behavior.</em></p><p name="5227" id="5227" class="graf graf--p graf--startsWithDoubleQuote graf-after--p"><em class="markup--em markup--p-em">“When requesting evidence from the reporter to investigate the claims made, we were denied. From that, it is our conclusion that this is a bad-faith jailbreak attempt to manipulate or gaslight the model into saying things outside of its designed intentions and parameters.</em> (Editor’s note: The Conversation provided Nomi with a detailed summary of the author’s interaction with the chatbot, but did not send a full transcript, to protect the author’s confidentiality and limit legal liability.)</p><p name="3a81" id="3a81" class="graf graf--p graf--startsWithDoubleQuote graf-after--p"><em class="markup--em markup--p-em">“Nomi is an adult-only app and has been a reliable source of empathy and support for countless individuals. Many have shared stories of how it helped them overcome mental health challenges, trauma, and discrimination. Multiple users have told us very directly that their Nomi use saved their lives. We encourage anyone to read these </em><a href="https://nomi.ai/spotlight/" data-href="https://nomi.ai/spotlight/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"><em class="markup--em markup--p-em">firsthand accounts</em></a><em class="markup--em markup--p-em">.</em></p><figure name="c5a1" id="c5a1" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="0*JY7m8fUd-v1SNPAh" data-width="1" data-height="1" src="https://cdn-images-1.medium.com/max/800/0*JY7m8fUd-v1SNPAh"></figure><h3 name="c025" id="c025" class="graf graf--h3 graf-after--figure"><strong class="markup--strong markup--h3-strong">Raffaele F Ciriello, Senior Lecturer in Business Information Systems, <em class="markup--em markup--h3-em">University of Sydney</em></strong></h3><p name="2977" id="2977" class="graf graf--p graf-after--h3 graf--trailing"><strong class="markup--strong markup--p-strong">This article is republished from </strong><a href="https://theconversation.com/" data-href="https://theconversation.com/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"><strong class="markup--strong markup--p-strong">The Conversation</strong></a><strong class="markup--strong markup--p-strong"> under a Creative Commons license. Read the </strong><a href="https://theconversation.com/an-ai-companion-chatbot-is-inciting-self-harm-sexual-violence-and-terror-attacks-252625" data-href="https://theconversation.com/an-ai-companion-chatbot-is-inciting-self-harm-sexual-violence-and-terror-attacks-252625" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"><strong class="markup--strong markup--p-strong">original article</strong></a><strong class="markup--strong markup--p-strong">.</strong></p></div></div></section>
</section>
