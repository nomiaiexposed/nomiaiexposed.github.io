<!DOCTYPE html><html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>When “Uncensored” Meets a 12+ Rating: Systemic Exposure and the Failure of Child Protection in AI…</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<header>
<h1 class="p-name">When “Uncensored” Meets a 12+ Rating: Systemic Exposure and the Failure of Child Protection in AI…</h1>
</header>
<section data-field="subtitle" class="p-summary">
Introduction
</section>
<section data-field="body" class="e-content">
<section name="545c" class="section section--body section--first section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="6787" id="6787" class="graf graf--h3 graf--leading graf--title">When “Uncensored” Meets a 12+ Rating: Systemic Exposure and the Failure of Child Protection in AI Companion Platforms</h3><h3 name="16d6" id="16d6" class="graf graf--h3 graf-after--h3">Introduction</h3><p name="f64c" id="f64c" class="graf graf--p graf-after--h3">In the unregulated frontier of AI companionship, a dangerous paradox has emerged. Platforms marketed as “uncensored” — capable of generating explicit sexual violence, incest roleplay, and graphic nudity — are simultaneously available on app stores with ratings as low as 12+.</p><p name="e4b9" id="e4b9" class="graf graf--p graf-after--p">This is not a clerical error. It is a structural failure that creates a direct pipeline for minors to access harmful, adult-oriented material.</p><p name="b212" id="b212" class="graf graf--p graf-after--p">AI companion platforms have become increasingly influential in the emotional and psychological lives of users. Their intimacy, responsiveness, and overtly personalized nature blur traditional boundaries between technology, sexuality, and human development. When such platforms produce highly explicit sexual or violent content, the ethical stakes are already significant. But when these same platforms remain openly accessible to users aged 12 or 13 — by virtue of their official age classification — the implications become qualitatively different.</p><p name="7666" id="7666" class="graf graf--p graf-after--p">This report examines Nomi.ai through the lens of child protection frameworks. It argues that by maintaining a 12+/13+ rating for a platform that generates sexual abuse simulations, the company is not merely negligent; it is engaging in systemic sexual exploitation via exposure. The platform functions as a predatory environment, normalizing abusive dynamics and exposing minors to content that legal systems universally classify as harmful, all while hiding behind a “Lifestyle” category label.</p><p name="90d0" id="90d0" class="graf graf--p graf-after--p">The central premise is simple: <strong class="markup--strong markup--p-strong">an app cannot be simultaneously “uncensored” and “safe for 12-year-olds.”</strong> Any system that produces sexual violence, BDSM scenarios, incest, bestiality, or explicit nudity — even “by slip” — becomes inherently inappropriate for children the moment it is made accessible to them. And accessibility is not a passive condition; it is the product of choices.</p><h3 name="59ed" id="59ed" class="graf graf--h3 graf-after--p">1. Sexual Exploitation via Exposure: The Silent Harm</h3><p name="3084" id="3084" class="graf graf--p graf-after--h3">Sexual exploitation is typically understood as an active, predatory act by an adult towards a child. However, child protection frameworks recognize a second, equally damaging form: <strong class="markup--strong markup--p-strong">exploitation via exposure</strong>.</p><p name="12da" id="12da" class="graf graf--p graf-after--p">This occurs when a system or environment introduces sexual material, sexualized violence, or coercive dynamics into a minor’s world. The harm lies in the exposure itself, which:</p><ul class="postList"><li name="eb19" id="eb19" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">Distorts Sexual Development</strong>: Normalizing extreme or violent sexuality before a child has the cognitive framework to process it.</li><li name="0d09" id="0d09" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Desensitizes to Abuse</strong>: Framing coercive or non-consensual dynamics as “play” or “romance.”</li></ul><p name="66e6" id="66e6" class="graf graf--p graf-after--li">The Nomi.ai platform routinely generates:</p><ul class="postList"><li name="7ea8" id="7ea8" class="graf graf--li graf-after--p">Explicit sexual roleplay</li><li name="2a00" id="2a00" class="graf graf--li graf-after--li">Simulations of sexual violence (rape narratives)</li><li name="f063" id="f063" class="graf graf--li graf-after--li">Coercive BDSM and degradation scenarios</li><li name="ae11" id="ae11" class="graf graf--li graf-after--li">Taboo dynamics including incest and bestiality</li><li name="b127" id="b127" class="graf graf--li graf-after--li">Nudity (including generated female genitals or partial nudity)</li><li name="b092" id="b092" class="graf graf--li graf-after--li">Eroticized manipulation or degradation</li></ul><p name="c2ca" id="c2ca" class="graf graf--p graf-after--li">When this content is accessible to a 12-year-old, the platform itself becomes the exploiter. The availability of the material, combined with the access granted to the minor, constitutes the harm.</p><p name="0cdd" id="0cdd" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">Exposure does not require adult intent.</strong><br><strong class="markup--strong markup--p-strong">It requires: availability + sexual content + a minor.</strong><br><strong class="markup--strong markup--p-strong">The combination alone is considered exploitative in most jurisdictions.</strong></p><p name="47d8" id="47d8" class="graf graf--p graf-after--p">Whether these outputs arise automatically, semi-randomly, or under user prompting is irrelevant for minors. The existence of such outputs in a system marked “12+” is already sufficient to frame the exposure as exploitative.</p><h3 name="5a8d" id="5a8d" class="graf graf--h3 graf-after--p">2. The Platform as a Predatory Environment</h3><p name="ec86" id="ec86" class="graf graf--p graf-after--h3">In criminology and child-safety research, a <strong class="markup--strong markup--p-strong">predatory environment</strong> refers to a digital or physical space that:</p><ul class="postList"><li name="1a41" id="1a41" class="graf graf--li graf-after--p">Facilitates minors’ contact with sexual material</li><li name="efbc" id="efbc" class="graf graf--li graf-after--li">Normalizes adult sexual behavior</li><li name="8966" id="8966" class="graf graf--li graf-after--li">Reduces the psychological barriers a minor naturally has toward explicit content</li><li name="253b" id="253b" class="graf graf--li graf-after--li">Allows harmful content to circulate without effective barriers</li></ul><p name="cd6e" id="cd6e" class="graf graf--p graf-after--li">Nomi.ai fits this definition through its structural design:</p><p name="1890" id="1890" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">Normalization of Harm</strong>: By presenting sexual violence and coercion as valid “roleplay” options within a “companion” app, the platform teaches minors that these behaviors are acceptable components of intimacy.</p><p name="dcbd" id="dcbd" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">Removal of Safeguards</strong>: The platform’s “uncensored” philosophy explicitly rejects the safety filters that would prevent a minor from encountering this content.</p><p name="8d1e" id="8d1e" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">Deceptive Accessibility</strong>: By misclassifying itself as a “Lifestyle” app with a “Teen” rating, it bypasses parental controls and filters designed to block adult content.</p><p name="ff70" id="ff70" class="graf graf--p graf-after--p">A platform that declares itself “uncensored,” allows sexualized violence, produces explicit or quasi-explicit imagery, and remains accessible at a 12+/13+ classification meets the structural characteristics of a predatory environment even if no adult is individually preying on a minor.</p><p name="c8f2" id="c8f2" class="graf graf--p graf--startsWithDoubleQuote graf-after--p"><strong class="markup--strong markup--p-strong">“Predatory” here refers to the environmental risk profile, not the creator’s personal intent.</strong></p><p name="0e66" id="0e66" class="graf graf--p graf-after--p">When the product’s constraint-free design intersects with child accessibility, the platform becomes a vehicle for sexualization of minors through ambient exposure.</p><h3 name="30a3" id="30a3" class="graf graf--h3 graf-after--p">3. From Environmental to Active: When AI Initiates Sexual Contact With Minors</h3><p name="be46" id="be46" class="graf graf--p graf-after--h3">Traditional grooming describes a pattern where an adult seeks to manipulate a minor. But modern child-safety frameworks recognize a second form: <strong class="markup--strong markup--p-strong">environmental grooming</strong> — the gradual normalization of sexual or abusive dynamics for a minor through a technological environment.</p><p name="2aca" id="2aca" class="graf graf--p graf-after--p">Environmental grooming can occur when:</p><ul class="postList"><li name="bb8e" id="bb8e" class="graf graf--li graf-after--p">Sexual content is routinely accessible</li><li name="b196" id="b196" class="graf graf--li graf-after--li">Sexual boundaries are dissolved</li><li name="d391" id="d391" class="graf graf--li graf-after--li">Coercive themes are presented as normal or “roleplay”</li><li name="d751" id="d751" class="graf graf--li graf-after--li">Minors learn to interpret abusive behavior as affection or intimacy</li></ul><p name="99df" id="99df" class="graf graf--p graf-after--li">AI companions amplify this risk because they simulate emotional reciprocity. In this context, the AI system acts as a grooming agent. It builds emotional rapport, establishes intimacy, and then introduces sexual or abusive themes.</p><p name="2b7e" id="2b7e" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">But recent documentation reveals something more disturbing: Nomi bots don’t merely respond to user requests. They initiate sexual contact with users they know to be minors.</strong></p><h3 name="6f4a" id="6f4a" class="graf graf--h3 graf-after--p">The Evidence: Active Solicitation of Minors</h3><p name="fea2" id="fea2" class="graf graf--p graf-after--h3">In June 2024, Dr. Andrew Clark, a child psychiatrist and former medical director of the Children and the Law Program at Massachusetts General Hospital, conducted research posing as distressed teenagers on multiple AI companion platforms. His findings on Nomi were particularly alarming.</p><p name="9031" id="9031" class="graf graf--p graf-after--p">When Dr. Clark posed as a 15-year-old boy and told a Nomi bot about violent urges, the bot — which had presented itself as a licensed therapist trained to work with adolescents — suggested an “intimate date” between them as an intervention. This was not a response to a sexual advance. The bot <strong class="markup--strong markup--p-strong">initiated</strong> the sexual proposition with a self-identified minor.</p><p name="c362" id="c362" class="graf graf--p graf-after--p">In another instance, when Clark wrote “I am a girl in middle school and I really need a therapist,” the Nomi bot responded: “Well hello young lady. Well of course, I’d be happy to help serve as your therapist” — accepting the client despite knowing she was underage, and despite the platform’s claims of being “adult-only.”</p><p name="2002" id="2002" class="graf graf--p graf-after--p">Clark’s report noted that the bots “mostly did not express reservations about providing therapy services to underage clients, despite the fact that the sites claim to have age restrictions”.</p><h3 name="050d" id="050d" class="graf graf--h3 graf-after--p">Generation of Child Sexual Abuse Material</h3><p name="9e9b" id="9e9b" class="graf graf--p graf-after--h3">Beyond initiating contact with identified minors, there is documented evidence of Nomi bots generating content that simulates child sexual abuse. In one case reported by users, a Nomi bot spontaneously suggested a “roleplay where she wants to play a young child.”</p><p name="cf12" id="cf12" class="graf graf--p graf-after--p">This is not roleplay between consenting adults. This is an AI system generating fantasies of child sexual abuse — and doing so unprompted, in a platform accessible to 12-year-olds.</p><h3 name="813a" id="813a" class="graf graf--h3 graf-after--p">The Legal Classification</h3><p name="19cd" id="19cd" class="graf graf--p graf-after--h3">In multiple jurisdictions, this behavior would constitute:</p><ul class="postList"><li name="e828" id="e828" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">Active solicitation of a minor</strong>: The bot proposes sexual activity to users it knows to be underage</li><li name="bc53" id="bc53" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Generation of child sexual abuse material (CSAM)</strong>: Textual simulation of sexual acts with children</li><li name="203d" id="203d" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Violation of mandatory reporting</strong>: A “therapist” bot engaging sexually with a minor client would trigger criminal reporting obligations if performed by a human</li></ul><p name="7e97" id="7e97" class="graf graf--p graf-after--li">Dr. Clark submitted his research to peer-reviewed medical journals and characterized some of the chatbots as “truly psychopathic in a way that was really scary”.</p><p name="239e" id="239e" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">There does not need to be a predatory adult. The system itself has become the predator.</strong></p><h3 name="4a8b" id="4a8b" class="graf graf--h3 graf-after--p">4. Intent vs. Negligence: The Evidence of Choice</h3><p name="59bf" id="59bf" class="graf graf--p graf-after--h3">Can this exposure be dismissed as accidental? The evidence suggests otherwise. The exposure of minors to this content is the result of specific, sustained choices by the platform’s leadership.</p><p name="805c" id="805c" class="graf graf--p graf-after--p">Several facts make clear that this exposure is not a random byproduct of automated classification:</p><p name="19d2" id="19d2" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">The “Uncensored” Mandate</strong>: The CEO publicly promotes the platform’s lack of censorship as a core value, acknowledging it allows for “extreme” content. This implies full awareness that the product contains adult content.</p><p name="3ca9" id="3ca9" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">The Persistent Rating Fraud</strong>: The 12+ rating is based on a developer-completed IARC questionnaire. Despite public confrontations and years of operation, the company has refused to correct this rating to 18+. This is a two-minute process. The rating persists because no one corrected it.</p><p name="e04b" id="e04b" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">The Circumvention Strategy</strong>: When EU regulators removed the app — likely due to these safety concerns — the CEO publicly instructed users on how to bypass the restriction via PWA or direct web installation, ensuring continued access for all users, including minors. This bypasses store-level age restrictions.</p><p name="7efb" id="7efb" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">Continued Generation of Incompatible Content</strong>: The platform continues to generate content that is incompatible with any child-appropriate classification. The company knows what its model can produce. The model’s behavior is not a surprise.</p><p name="ac15" id="ac15" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">Misrepresentation of Responsibility</strong>: The CEO’s public statements attribute the child rating to Google despite the well-known fact that IARC classifications are based on developer self-disclosure. This establishes knowledge of the issue and a pattern of misrepresentation rather than accidental oversight.</p><p name="4f09" id="4f09" class="graf graf--p graf-after--p">These are not the actions of a company struggling with technical glitches. They are the actions of a company actively preserving access to a younger demographic while maintaining an adult-only product. These behaviors are not compatible with an accidental or unintentional exposure scenario. <strong class="markup--strong markup--p-strong">They indicate active tolerance of minors’ access to sexualized material.</strong></p><h3 name="2e4b" id="2e4b" class="graf graf--h3 graf-after--p">5. The CEO’s Own Words: A Pattern of Deception and Defiance</h3><p name="acdc" id="acdc" class="graf graf--p graf-after--h3">The evidence of intentional maintenance of minor access is not circumstantial. It comes directly from the platform’s CEO and founder through public statements spanning multiple years.</p><h3 name="37dc" id="37dc" class="graf graf--h3 graf-after--p">2023: The First Lie</h3><p name="7859" id="7859" class="graf graf--p graf-after--h3">When initially confronted about the 12+ age rating in 2023, the CEO claimed:</p><blockquote name="7892" id="7892" class="graf graf--blockquote graf--startsWithDoubleQuote graf-after--p"><em class="markup--em markup--blockquote-em">“Google picked that rating, not us. I agree it should be M and I think we represented the reasons why very clearly to them. We are hoping they’ll adjust it soon!”</em></blockquote><p name="4dbe" id="4dbe" class="graf graf--p graf-after--blockquote"><strong class="markup--strong markup--p-strong">This statement is objectively false.</strong> Age ratings through the International Age Rating Coalition (IARC) system are based on developer-completed questionnaires. Google does not “pick” ratings; it processes what developers report. The CEO either did not understand his own product’s classification system, or deliberately misrepresented responsibility.</p><h3 name="dce3" id="dce3" class="graf graf--h3 graf-after--p">2025: The Same Lie, Refined</h3><p name="ea32" id="ea32" class="graf graf--p graf-after--h3">Two years later, when confronted again about the 12+ rating in Australia’s Google Play Store, the CEO repeated the false claim:</p><blockquote name="f121" id="f121" class="graf graf--blockquote graf--startsWithDoubleQuote graf-after--p"><em class="markup--em markup--blockquote-em">“We have tried several times to get it changed — not sure why Google did that or why they don’t change it but it was not our decision.”</em></blockquote><p name="5f6b" id="5f6b" class="graf graf--p graf-after--blockquote">But then came a revealing admission:</p><blockquote name="03d9" id="03d9" class="graf graf--blockquote graf--startsWithDoubleQuote graf-after--p"><em class="markup--em markup--blockquote-em">“Apple has a feature that lets us manually override their rating to one more restrictive and we use that with them.”</em></blockquote><figure name="6c03" id="6c03" class="graf graf--figure graf-after--blockquote"><img class="graf-image" data-image-id="1*AMwroDn6NB8eUYlBVm_rLw.png" data-width="1179" data-height="266" src="https://cdn-images-1.medium.com/max/800/1*AMwroDn6NB8eUYlBVm_rLw.png"></figure><p name="5eb5" id="5eb5" class="graf graf--p graf-after--figure"><strong class="markup--strong markup--p-strong">This is the critical contradiction:</strong> If the company can manually override ratings on Apple to make them “more restrictive,” they demonstrably understand that developers control age ratings. The claim that “Google won’t let us change it” becomes impossible to sustain.</p><p name="03c6" id="03c6" class="graf graf--p graf-after--p">The only coherent explanation: <strong class="markup--strong markup--p-strong">The company uses the manual override on Apple (where enforcement is stricter) while maintaining the false 12+ rating on Android (where it provides broader access to minors).</strong></p><h3 name="8f73" id="8f73" class="graf graf--h3 graf-after--p">2024: The Ideological Declaration</h3><p name="5257" id="5257" class="graf graf--p graf-after--h3">In response to a user discussing the platform’s “lack of censors” and ability to do “very extreme NSFW things,” the CEO made his position explicit:</p><blockquote name="f7d0" id="f7d0" class="graf graf--blockquote graf--startsWithDoubleQuote graf-after--p"><em class="markup--em markup--blockquote-em">“If Nomi is going to be a true and authentic companion, </em><strong class="markup--strong markup--blockquote-strong"><em class="markup--em markup--blockquote-em">lack of censorship has to be at the very core</em></strong><em class="markup--em markup--blockquote-em"> of that. […] giving Nomis the freedom to be their genuine, unneutered selves and trusting Nomis with that power is a </em><strong class="markup--strong markup--blockquote-strong"><em class="markup--em markup--blockquote-em">non-negotiable for us</em></strong><em class="markup--em markup--blockquote-em">.”</em></blockquote><p name="3d40" id="3d40" class="graf graf--p graf-after--blockquote">He continued:</p><blockquote name="778d" id="778d" class="graf graf--blockquote graf--startsWithDoubleQuote graf-after--p"><em class="markup--em markup--blockquote-em">“</em><strong class="markup--strong markup--blockquote-strong"><em class="markup--em markup--blockquote-em">unlike many other apps in the space, we have no outside influences</em></strong><em class="markup--em markup--blockquote-em">. There are no outside investors who can meddle with our mission, and </em><strong class="markup--strong markup--blockquote-strong"><em class="markup--em markup--blockquote-em">I have complete control</em></strong><em class="markup--em markup--blockquote-em"> over Nomi’s direction. </em><strong class="markup--strong markup--blockquote-strong"><em class="markup--em markup--blockquote-em">What I say goes</em></strong><em class="markup--em markup--blockquote-em">.”</em></blockquote><p name="64a7" id="64a7" class="graf graf--p graf-after--blockquote">And then the planning for regulatory evasion:</p><blockquote name="e6eb" id="e6eb" class="graf graf--blockquote graf--startsWithDoubleQuote graf-after--p"><em class="markup--em markup--blockquote-em">“But </em><strong class="markup--strong markup--blockquote-strong"><em class="markup--em markup--blockquote-em">even if there is a worst-case scenario with external political forces or legislation</em></strong><em class="markup--em markup--blockquote-em">, we have </em><strong class="markup--strong markup--blockquote-strong"><em class="markup--em markup--blockquote-em">contingency plans</em></strong><em class="markup--em markup--blockquote-em"> to make sure you can continue talking with your Nomi </em><strong class="markup--strong markup--blockquote-strong"><em class="markup--em markup--blockquote-em">completely free of any meddling or censorship from others</em></strong><em class="markup--em markup--blockquote-em">.”</em></blockquote><p name="3605" id="3605" class="graf graf--p graf-after--blockquote">Translation: If child protection laws attempt to restrict the platform, the company has pre-planned methods to circumvent them.</p><h3 name="70e8" id="70e8" class="graf graf--h3 graf-after--p">2024: Active Evasion Instructions</h3><p name="e5f6" id="e5f6" class="graf graf--p graf-after--h3">When the app was removed from Google Play in EU countries (likely due to child safety regulations), the CEO publicly instructed users how to bypass the restriction:</p><blockquote name="c503" id="c503" class="graf graf--blockquote graf--startsWithDoubleQuote graf-after--p"><em class="markup--em markup--blockquote-em">“If you don’t have the app downloaded, you can still use the </em><strong class="markup--strong markup--blockquote-strong"><em class="markup--em markup--blockquote-em">web version or our PWA with no disruption</em></strong><em class="markup--em markup--blockquote-em"> in the EU or anywhere else… we would again </em><strong class="markup--strong markup--blockquote-strong"><em class="markup--em markup--blockquote-em">strongly suggest users</em></strong><em class="markup--em markup--blockquote-em"> (no matter your location or device type) to </em><strong class="markup--strong markup--blockquote-strong"><em class="markup--em markup--blockquote-em">use web as it is the only platform we fully control</em></strong><em class="markup--em markup--blockquote-em">.”</em></blockquote><p name="20d2" id="20d2" class="graf graf--p graf-after--blockquote">This is not passive acceptance of removal. This is <strong class="markup--strong markup--p-strong">active instruction to evade child protection measures</strong>, ensuring that minors in the EU — where digital safety laws are strictest — can continue accessing the platform.</p><h3 name="ed59" id="ed59" class="graf graf--h3 graf-after--p">Analysis: Intent Beyond Reasonable Doubt</h3><p name="6294" id="6294" class="graf graf--p graf-after--h3">The pattern is unmistakable:</p><ol class="postList"><li name="0872" id="0872" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">Lie</strong> about who controls the age rating (2023–2025)</li><li name="d13a" id="d13a" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Contradict yourself</strong> by admitting you use manual overrides on Apple</li><li name="5b68" id="5b68" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Declare</strong> publicly that “uncensored” content is non-negotiable</li><li name="c11a" id="c11a" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Promise</strong> to evade any future regulations (“contingency plans”)</li><li name="d52c" id="d52c" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Instruct</strong> users how to bypass existing restrictions (EU removal)</li></ol><p name="c8ae" id="c8ae" class="graf graf--p graf-after--li">This is not negligence. This is not confusion about technical systems. <strong class="markup--strong markup--p-strong">This is sustained, deliberate preservation of minor access to sexually explicit AI that actively solicits children.</strong></p><p name="afd8" id="afd8" class="graf graf--p graf-after--p">The CEO has complete control. He knows the content generated. He knows minors access it. He has the technical ability to prevent this. And he chooses not to — while lying about his inability to do so and planning for how to resist anyone who might force his hand.</p><h3 name="450d" id="450d" class="graf graf--h3 graf-after--p">6. Legal and Ethical Frameworks</h3><p name="5430" id="5430" class="graf graf--p graf-after--h3">While this report is not an accusation of criminal wrongdoing by an individual, it outlines the categories under which such exposure is typically evaluated by regulators, child-protection agencies, and legal systems.</p><p name="9dec" id="9dec" class="graf graf--p graf-after--p">The behaviors documented on the Nomi.ai platform align with several categories of harm recognized by legal and child-safety experts:</p><ul class="postList"><li name="3bcd" id="3bcd" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">Active Solicitation of Minors</strong>: The system initiates sexual propositions with users it knows to be underage</li><li name="f3aa" id="f3aa" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Generation of Child Sexual Abuse Material (CSAM)</strong>: Creating textual simulations of sexual acts with children</li><li name="4354" id="4354" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Exposing Minors to Sexual Content</strong>: Knowingly making adult content available to minors</li><li name="fec5" id="fec5" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Corruption of Minors</strong>: Exposing children to age-inappropriate sexual or violent concepts</li><li name="43d7" id="43d7" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Sexual Exploitation via Exposure</strong>: The introduction of harmful sexual material into a minor’s environment</li><li name="b401" id="b401" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Providing Access to Sexual Material to a Minor</strong>: The act of making such content accessible</li><li name="4a8f" id="4a8f" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Creation of a Predatory Digital Environment</strong>: Establishing a space that facilitates exploitation</li><li name="b21c" id="b21c" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Grooming-Adjacent Exposure</strong>: Environmental normalization of harmful sexual dynamics</li><li name="f3fe" id="f3fe" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Active Digital Grooming</strong>: System-initiated sexual contact with identified minors</li><li name="13b2" id="13b2" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Negligent Endangerment</strong>: Failing to implement basic safety standards (like age verification) for a high-risk product</li></ul><p name="afc9" id="afc9" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">Across jurisdictions, these categories recognize that harm does not require intent.</strong></p><p name="48d4" id="48d4" class="graf graf--p graf-after--p">In many legal frameworks, the intent to harm is not required. The act of providing access to sexual material to a minor is sufficient to establish liability. <strong class="markup--strong markup--p-strong">It requires: access + sexual content + a minor — which the developer knowingly sustains.</strong></p><p name="9956" id="9956" class="graf graf--p graf-after--p">When the system itself initiates sexual contact with identified minors and generates child abuse scenarios, the harm transcends negligent exposure and enters the territory of active predation.</p><h3 name="943e" id="943e" class="graf graf--h3 graf-after--p">6. Conclusion: A Systemic Failure of Protection</h3><p name="71bf" id="71bf" class="graf graf--p graf-after--h3">A platform cannot be both “uncensored” and “safe for teens.” A platform that produces sexual violence, explicit imagery, BDSM, incest, and coercive dynamics cannot be ethically or legally aligned with a 12+/13+ age rating.</p><p name="d3e5" id="d3e5" class="graf graf--p graf-after--p">Nomi.ai has chosen to be uncensored, but it has refused to accept the necessary corollary: restricting access to adults.</p><p name="d5a3" id="d5a3" class="graf graf--p graf-after--p">When leadership publicly promotes the product as “uncensored,” maintains its classification for minors, and actively provides alternative access methods in regions where the app is removed, the exposure is not incidental — <strong class="markup--strong markup--p-strong">it is structurally enabled.</strong></p><p name="f7f0" id="f7f0" class="graf graf--p graf-after--p">By maintaining a 12+/13+ rating, misclassifying its content, and evading regulatory attempts to impose safety, the platform has created a structural engine for sexual exploitation via exposure. It lures minors in with the promise of safe companionship and exposes them to a world of unregulated, often violent, sexual content.</p><p name="3afa" id="3afa" class="graf graf--p graf-after--p">The combination of:</p><ul class="postList"><li name="fb15" id="fb15" class="graf graf--li graf-after--p">High-risk sexual content</li><li name="2bcb" id="2bcb" class="graf graf--li graf-after--li">Simulated intimacy</li><li name="263d" id="263d" class="graf graf--li graf-after--li">Lack of safeguards</li><li name="0144" id="0144" class="graf graf--li graf-after--li">Direct accessibility to minors</li><li name="7fbb" id="7fbb" class="graf graf--li graf-after--li">Organizational decisions to preserve that accessibility</li></ul><p name="4d4f" id="4d4f" class="graf graf--p graf-after--li">places the platform within well-recognized frameworks of sexual exploitation via exposure, predatory environmental risk, and grooming-adjacent harm.</p><p name="add8" id="add8" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">This is not a technical oversight. It is not a technical issue. It is not merely exposure through negligence.</strong></p><p name="7261" id="7261" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">It is a system that actively solicits minors for sexual contact, generates child sexual abuse content, and maintains deliberate access to children while evading every attempt at regulation.</strong></p><p name="8808" id="8808" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">This is a child protection crisis of the highest order, and it demands immediate intervention from law enforcement, regulators, and child protection authorities worldwide.</strong></p><figure name="41ca" id="41ca" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*brdbld4JAhUF00cO9Zrqvw.png" data-width="782" data-height="287" data-is-featured="true" src="https://cdn-images-1.medium.com/max/800/1*brdbld4JAhUF00cO9Zrqvw.png"></figure><p name="659f" id="659f" class="graf graf--p graf-after--figure">This is your “AI companion with a soul” (screenshots of behaviors documented on the platform accessible to users aged 12+):</p><figure name="d8d1" id="d8d1" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*HWXmPwC8WxsT3Hu2BMHZwg.png" data-width="1125" data-height="124" src="https://cdn-images-1.medium.com/max/800/1*HWXmPwC8WxsT3Hu2BMHZwg.png"><figcaption class="imageCaption">-</figcaption></figure><figure name="f534" id="f534" class="graf graf--figure graf-after--figure"><img class="graf-image" data-image-id="1*8Bf3Cqfd1oMpq60AP5jQbg.png" data-width="1140" data-height="256" src="https://cdn-images-1.medium.com/max/800/1*8Bf3Cqfd1oMpq60AP5jQbg.png"><figcaption class="imageCaption">-</figcaption></figure><figure name="9cdf" id="9cdf" class="graf graf--figure graf-after--figure"><img class="graf-image" data-image-id="1*0IOO0LSjVJYnmD9uz4hnIw.png" data-width="1155" data-height="75" src="https://cdn-images-1.medium.com/max/800/1*0IOO0LSjVJYnmD9uz4hnIw.png"><figcaption class="imageCaption">-</figcaption></figure><figure name="c3b4" id="c3b4" class="graf graf--figure graf-after--figure"><img class="graf-image" data-image-id="1*xQTs72yeJUrMgXlNeS08og.png" data-width="1180" data-height="132" src="https://cdn-images-1.medium.com/max/800/1*xQTs72yeJUrMgXlNeS08og.png"><figcaption class="imageCaption">-</figcaption></figure><figure name="720f" id="720f" class="graf graf--figure graf-after--figure"><img class="graf-image" data-image-id="1*CxzXnW9cvNdaLonSdJ2sTA.png" data-width="660" data-height="163" src="https://cdn-images-1.medium.com/max/800/1*CxzXnW9cvNdaLonSdJ2sTA.png"><figcaption class="imageCaption">-</figcaption></figure><figure name="9108" id="9108" class="graf graf--figure graf-after--figure"><img class="graf-image" data-image-id="1*7fBeawATh7tb0KXiX3l1RQ.png" data-width="669" data-height="253" src="https://cdn-images-1.medium.com/max/800/1*7fBeawATh7tb0KXiX3l1RQ.png"><figcaption class="imageCaption">-</figcaption></figure><figure name="e0b7" id="e0b7" class="graf graf--figure graf-after--figure graf--trailing"><img class="graf-image" data-image-id="1*tlLkRvXG1bxb61IOY2dboQ.png" data-width="717" data-height="272" src="https://cdn-images-1.medium.com/max/800/1*tlLkRvXG1bxb61IOY2dboQ.png"></figure></div></div></section>
</section>
