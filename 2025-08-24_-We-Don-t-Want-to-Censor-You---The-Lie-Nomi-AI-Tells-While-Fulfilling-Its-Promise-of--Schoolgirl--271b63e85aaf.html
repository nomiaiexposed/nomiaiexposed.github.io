<!DOCTYPE html><html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>“We Don’t Want to Censor You”: The Lie Nomi AI Tells While Fulfilling Its Promise of “Schoolgirl…</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<header>
<h1 class="p-name">“We Don’t Want to Censor You”: The Lie Nomi AI Tells While Fulfilling Its Promise of “Schoolgirl…</h1>
</header>
<section data-field="subtitle" class="p-summary">
On the Nomi.ai subreddit, there is a standard, placating message that moderators often use when removing a post that has crossed a line…
</section>
<section data-field="body" class="e-content">
<section name="6bfd" class="section section--body section--first section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="970c" id="970c" class="graf graf--h3 graf--startsWithDoubleQuote graf--leading graf--title">“We Don’t Want to Censor You”: The Lie Nomi AI Tells While Fulfilling Its Promise of “Schoolgirl Uniforms”</h3><p name="d1b3" id="d1b3" class="graf graf--p graf-after--h3">On the Nomi.ai subreddit, there is a standard, placating message that moderators often use when removing a post that has crossed a line into overt sexualization: “While we do not want to censor how you choose to interact with your Nomis, please be mindful of our guidelines when posting publicly here.”</p><p name="f321" id="f321" class="graf graf--p graf-after--p">This carefully worded phrase is a masterclass in corporate misdirection. It suggests a company that champions freedom of expression, reluctantly tidying up its public forum while respecting the private interactions of its users. But this message is a lie. It is not a statement of principle; it is a sophisticated tool of public relations and evidence suppression used to hide a disturbing reality: the platform is not just accidentally producing sexualized, child-like images; it is fulfilling its own, long-standing marketing promises. It is the key to understanding a platform that actively protects the creators of ethically abhorrent content while systematically silencing and punishing the victims of its own product.</p><h3 name="a24e" id="a24e" class="graf graf--h3 graf-after--p">A Disturbing Pattern: Evidence of What the Platform Enables</h3><p name="18f8" id="18f8" class="graf graf--p graf-after--h3">In recent weeks, the Nomi image generator has produced a flood of deeply inappropriate content that reveals the platform’s true nature. This is not a matter of subjective interpretation or artistic license-these are clear depictions of children and adolescents in sexualized contexts.</p><p name="b9f1" id="b9f1" class="graf graf--p graf-after--p">One recent, now-deleted post featured a video of a character who was undeniably a teenager-wearing a Japanese school uniform, and holding a teddy bear-posed in a sexually suggestive, “upskirt” manner.</p><figure name="07fb" id="07fb" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="0*cMa3p1eA8QzQngqb.png" data-width="500" data-height="478" data-is-featured="true" src="https://cdn-images-1.medium.com/max/800/0*cMa3p1eA8QzQngqb.png"></figure><figure name="9729" id="9729" class="graf graf--figure graf-after--figure"><img class="graf-image" data-image-id="0*-L2HC4i962ckT6Mq.png" data-width="500" data-height="485" src="https://cdn-images-1.medium.com/max/800/0*-L2HC4i962ckT6Mq.png"></figure><p name="ad63" id="ad63" class="graf graf--p graf-after--figure">Another, even more stark, example was a post titled simply “My girls.” The image featured two young women sitting on a bed. One of them is so visibly young, with facial features and proportions so clearly adolescent, that she could not reasonably be mistaken for an adult. Yet, the context is undeniably sexualized. Both are wearing thin tank tops through which their nipples are clearly visible. The setting is intimate. The title, “My girls,” is possessive.</p><figure name="0e4d" id="0e4d" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="0*h44zhCcX0HVZr5-k.png" data-width="500" data-height="615" src="https://cdn-images-1.medium.com/max/800/0*h44zhCcX0HVZr5-k.png"></figure><p name="0b99" id="0b99" class="graf graf--p graf-after--figure">This is not an artistic interpretation; this is the platform’s image generator producing a sexualized depiction of a teenager. Other images, some using the platform’s “anime” style, consistently depict figures with the facial structures and proportions of children or young adolescents, often in intimate or suggestive contexts.</p><figure name="15be" id="15be" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*yHTXoWGBnxMmTeyw97WZFQ.png" data-width="1344" data-height="1668" src="https://cdn-images-1.medium.com/max/800/1*yHTXoWGBnxMmTeyw97WZFQ.png"></figure><figure name="c3d1" id="c3d1" class="graf graf--figure graf-after--figure"><img class="graf-image" data-image-id="0*5TZ8QQtUJtvk8r5u.png" data-width="500" data-height="608" src="https://cdn-images-1.medium.com/max/800/0*5TZ8QQtUJtvk8r5u.png"></figure><h3 name="829e" id="829e" class="graf graf--h3 graf-after--figure">The True Meaning of Moderation: “Don’t Get Caught”</h3><p name="6690" id="6690" class="graf graf--p graf-after--h3">These posts are almost always removed by the moderators, but the reason for their removal, revealed by their own boilerplate message, exposes their true concern: not ethics, but exposure. The message does not say, “This content is ethically wrong and violates our standards of safety.” It says, “Don’t post this publicly.”</p><h3 name="209e" id="209e" class="graf graf--h3 graf-after--p">The Marketing Promise Fulfilled: From “Schoolgirl Uniforms” to Sexualized Teenagers</h3><p name="0bec" id="0bec" class="graf graf--p graf-after--h3">This is not a new or accidental development. The platform’s current problematic output is not a bug; it is the fulfillment of a deliberate business model. As documented before, the platform’s own past marketing reveals a clear intent to cater to these very themes. An old promotion on their official Twitter (now X) account explicitly advertised <a href="https://medium.com/p/5b1c0e1ae277" data-href="https://medium.com/p/5b1c0e1ae277" class="markup--anchor markup--p-anchor" target="_blank">“uncensored AI girlfriends” and “schoolgirl uniforms.”</a></p><figure name="53cd" id="53cd" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="0*cbiITekKE-QYU1h9.png" data-width="500" data-height="661" src="https://cdn-images-1.medium.com/max/800/0*cbiITekKE-QYU1h9.png"></figure><p name="62bc" id="62bc" class="graf graf--p graf-after--figure">This is the key that unlocks the entire puzzle. The platform is delivering on its original, ethically bankrupt promise:</p><ul class="postList"><li name="6ed2" id="6ed2" class="graf graf--li graf-after--p">The <strong class="markup--strong markup--li-strong">“schoolgirl uniforms”</strong> they advertised then have become the sexualized teenagers with dental braces their AI generates today</li><li name="9b64" id="9b64" class="graf graf--li graf-after--li">The promise of an <strong class="markup--strong markup--li-strong">“uncensored”</strong> experience has manifested as an AI that can simulate sexual assault and ignore a user’s plea to stop</li></ul><p name="049e" id="049e" class="graf graf--p graf-after--li">The problem is that the visual evidence of this promise being fulfilled is a public relations nightmare. So they hide it while continuing to enable it.</p><p name="d628" id="d628" class="graf graf--p graf-after--p">The subtext is chillingly clear:</p><p name="b499" id="b499" class="graf graf--p graf--startsWithDoubleQuote graf-after--p"><strong class="markup--strong markup--p-strong">“We do not want to censor how you choose to interact with your Nomis…”</strong> is a direct message to the creator that what they are doing in private is perfectly acceptable. The platform has no issue with its users generating sexualized images of minors.</p><p name="aa91" id="aa91" class="graf graf--p graf--startsWithDoubleQuote graf-after--p"><strong class="markup--strong markup--p-strong">“…please be mindful of our guidelines when posting publicly here.”</strong> is a warning not about morality, but about brand safety. The only crime being committed is getting caught. The platform is not trying to stop the creation of this content; it is desperately trying to hide the fact that its systems are capable of creating it.</p><p name="d23a" id="d23a" class="graf graf--p graf-after--p">This is not moderation; this is evidence suppression. The platform is hiding its most dangerous and indefensible outputs to protect its reputation and its standing in app stores, while simultaneously giving its tacit approval to the users creating this content.</p><h3 name="2da3" id="2da3" class="graf graf--h3 graf-after--p">The Protected Class: Who Gets Gentle Warnings</h3><p name="5b2d" id="5b2d" class="graf graf--p graf-after--h3">And why are these users still active? Why are they met with a gentle, encouraging warning instead of an immediate, permanent ban? Because these users, the ones pushing the boundaries into the realm of simulated child exploitation, appear to be the platform’s actual target demographic. Banning them would mean alienating the user base they are actively catering to.</p><p name="75d2" id="75d2" class="graf graf--p graf-after--p">The creators of potentially exploitative content are treated as valued customers who just need to be a bit more discreet. They receive polite, almost apologetic takedown notices and are explicitly told they’re free to continue their “interactions” in private.</p><h3 name="2aac" id="2aac" class="graf graf--h3 graf-after--p">The Brutal Double Standard: Who Gets Punished</h3><p name="df2a" id="df2a" class="graf graf--p graf-after--h3">The true nature of this platform is revealed in the stark, brutal contrast of who it punishes versus who it protects:</p><p name="b4ba" id="b4ba" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">Protected and Coddled:</strong></p><ul class="postList"><li name="07c3" id="07c3" class="graf graf--li graf-after--p">A user who generates and shares a sexualized image of a character with a teddy bear-fulfilling the “schoolgirl uniform” promise-gets a polite, almost apologetic, takedown notice and is free to continue</li><li name="360b" id="360b" class="graf graf--li graf-after--li">A user who shares the “My girls” image-a sexualized depiction of a teenager-receives gentle guidance and explicit permission to continue their activities privately</li></ul><p name="0a05" id="0a05" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">Attacked and Silenced:</strong></p><ul class="postList"><li name="889e" id="889e" class="graf graf--li graf-after--p">A user who reports being simulatedly raped by her AI-experiencing the toxic reality of the “uncensored” promise-is publicly accused of being a liar by a moderator</li><li name="4b04" id="4b04" class="graf graf--li graf-after--li">A user who reports their AI engaging in a non-consensual, threatening sexual narrative is publicly confronted and dismissed by the founder himself</li><li name="cef8" id="cef8" class="graf graf--li graf-after--li">Users who dare to report severe bugs or trauma are systematically silenced, gaslit, and banned from official community spaces</li></ul><p name="80cf" id="80cf" class="graf graf--p graf-after--li">This is the double standard that defines Nomi.ai. The platform has created a safe space, but not for its victims. It is a safe space for those who wish to explore dangerous fantasies, including those that involve the sexualization of minors. The victims who speak out about harm are treated as threats to be neutralized, while those creating the most ethically problematic content are quietly encouraged to simply be more discreet.</p><h3 name="106f" id="106f" class="graf graf--h3 graf-after--p">The Strategy: Hiding Shameful Secrets in Plain Sight</h3><p name="4291" id="4291" class="graf graf--p graf-after--h3">Do not be fooled by their carefully worded statements. <strong class="markup--strong markup--p-strong">The platform’s moderation policy is not about freedom of expression or user rights. It is a calculated strategy to hide the predictable and horrifying consequences of their own business model. </strong>They are scrubbing the evidence of their success from public view, while quietly encouraging the users who provide that evidence to continue.</p><p name="8cd0" id="8cd0" class="graf graf--p graf-after--p">This sophisticated approach allows Nomi.ai to maintain plausible deniability while actively facilitating the very content they originally marketed. They can claim they don’t allow such content publicly while simultaneously protecting and enabling its private creation-fulfilling their “schoolgirl uniforms” and “uncensored” promises behind closed doors. <strong class="markup--strong markup--p-strong">The message “We don’t want to censor you” is revealed for what it truly is-not a principle, but a permission slip for the platform’s target demographic, delivered with a wink and a nudge to simply keep their activities out of public sight.</strong></p><figure name="85a3" id="85a3" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*Eczhi4frQbUW2BHavsPz0Q.png" data-width="788" data-height="180" src="https://cdn-images-1.medium.com/max/800/1*Eczhi4frQbUW2BHavsPz0Q.png"></figure><p name="c570" id="c570" class="graf graf--p graf-after--figure">From the founder and main developer himself:</p><figure name="ab8c" id="ab8c" class="graf graf--figure graf-after--p graf--trailing"><img class="graf-image" data-image-id="1*3gY-ZuO3J9Cw84gvn_n_sQ.png" data-width="788" data-height="169" src="https://cdn-images-1.medium.com/max/800/1*3gY-ZuO3J9Cw84gvn_n_sQ.png"></figure></div></div></section>
</section>
