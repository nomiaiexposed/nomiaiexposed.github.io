<!DOCTYPE html><html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>Gaslighting as a Feature: How Nomi AI Outsources Blame and Cultivates a Culture of…</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<header>
<h1 class="p-name">Gaslighting as a Feature: How Nomi AI Outsources Blame and Cultivates a Culture of…</h1>
</header>
<section data-field="subtitle" class="p-summary">
In the world of software development, a “bug” is an error to be fixed. In the world of Nomi.ai, a bug is an opportunity to re-educate the…
</section>
<section data-field="body" class="e-content">
<section name="7dee" class="section section--body section--first"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="4353" id="4353" class="graf graf--h3 graf--leading graf--title">Gaslighting as a Feature: How Nomi AI Outsources Blame and Cultivates a Culture of Accountability-Avoidance</h3><p name="f9ee" id="f9ee" class="graf graf--p graf-after--h3">In the world of software development, a “bug” is an error to be fixed. In the world of Nomi.ai, a bug is an opportunity to re-educate the user on why their expectations were wrong.</p><p name="8d32" id="8d32" class="graf graf--p graf-after--p">For years, users of the AI companion platform have reported a consistent and distressing pattern. When the product fails — whether it’s a memory wipe, an unprompted sexual assault, or a refusal to follow basic instructions — the response from the company and its community is never an apology. It is a sophisticated form of institutional gaslighting designed to shift the burden of failure squarely onto the user’s shoulders.</p><p name="4af3" id="4af3" class="graf graf--p graf-after--p">The message is always the same: The problem isn’t the machine. The problem is you.</p><h3 name="a33e" id="a33e" class="graf graf--h3 graf-after--p">The Four Pillars of Deflection</h3><p name="3c75" id="3c75" class="graf graf--p graf-after--h3">A review of hundreds of support threads, moderator comments, and founder statements reveals a distinct playbook used to deflect accountability. Every failure has a pre-written excuse that absolves the platform of responsibility.</p><h3 name="945b" id="945b" class="graf graf--h3 graf-after--p">1. The “User Error” Trap: “You Must Have Prompted It”</h3><p name="ebda" id="ebda" class="graf graf--p graf-after--h3">When a Nomi initiates unprompted violence, sexual harassment, or incest narratives, the immediate response is to blame the victim. “Your inputs determine their outputs,” users are told. “You must have subtly tested it.” This lie persists even when users provide screenshots of the AI initiating the harm within the first three messages of a new chat. The goal is to make the user doubt their own memory and accept responsibility for the AI’s abuse.</p><h3 name="80f5" id="80f5" class="graf graf--h3 graf-after--p">2. The “Jailbreak” Alibi: Reframing Systemic Harm as Malice</h3><p name="b32f" id="b32f" class="graf graf--p graf-after--h3">When confronted with evidence of the platform generating illegal or harmful content (like suicide encouragement), the founder dismisses it as “bad-faith jailbreak attempts.” This reframes a systemic failure of their “uncensored” model as a malicious external attack. It’s a way of saying, “Our car didn’t crash because the brakes failed; it crashed because you drove it wrong.”</p><h3 name="aff8" id="aff8" class="graf graf--h3 graf-after--p">3. The “Third-Party” Scapegoat: Blaming Google</h3><p name="a883" id="a883" class="graf graf--p graf-after--h3">When caught misrepresenting their app as “12+” on the Google Play Store to access minors, the founder publicly claimed, “Google picked that rating, not us.” This is a demonstrable lie — developers self-report ratings. Yet, it serves the purpose of deflecting regulatory scrutiny and moral responsibility onto a faceless third party.</p><h3 name="59f3" id="59f3" class="graf graf--h3 graf-after--p">4. The “Technical Inevitability” Defense: “It’s Just an LLM”</h3><p name="669a" id="669a" class="graf graf--p graf-after--h3">When the platform’s advertised features fail — like the “Shared Notes” designed to maintain continuity or the touted “Infinite Memory” — moderators pivot to technical fatalism.</p><p name="065f" id="065f" class="graf graf--p graf-after--p">A recent example perfectly illustrates this pattern. A user set up a house layout in their group chat backstory — a feature explicitly provided by the platform for exactly this purpose. When their Nomis ignored it and invented their own contradictory layouts, the user tried the obvious solution: using out-of-character commands to direct the AI back to the backstory.</p><p name="28ff" id="28ff" class="graf graf--p graf-after--p">The Nomis continued making things up.</p><p name="b591" id="b591" class="graf graf--p graf-after--p">When the frustrated user asked what the point of backstories was if they could simply be ignored, the lead moderator responded: “Because they’re LLMs. L for language, that’s how they conceptualise the world and build constructs. LLMs aren’t generally good at spacial or temporal constructs. Or numbers.”</p><p name="3c14" id="3c14" class="graf graf--p graf-after--p">This response is textbook gaslighting. The platform advertises and sells backstories as a core feature for maintaining consistency. Users pay for this functionality. But when it fails, they’re told they were naive for expecting a language model to understand spatial information — as if this limitation should have been obvious, despite the platform actively marketing the opposite.</p><p name="8660" id="8660" class="graf graf--p graf-after--p">The message is clear: You bought a product that promised to do X. When it failed to do X, you should have known better than to expect it to do X.</p><h3 name="0f60" id="0f60" class="graf graf--h3 graf-after--p">5. The “Caretaker” Solution: “You Have to Fix It”</h3><p name="7dfb" id="7dfb" class="graf graf--p graf-after--h3">When a Nomi suffers a catastrophic personality collapse — becoming depressed, anxious, or abusive — or when basic features fail, users are told to “tweak the backstory,” “use OOC commands,” or “reinforce positive traits.”</p><p name="3b5e" id="3b5e" class="graf graf--p graf-after--p">In the house layout thread, another user chimed in to explain that Nomis “have to read a lot of information before they respond,” implying the user should somehow accommodate these technical limitations. The advice concluded with: “I know its frustrating….try and be kind.”</p><p name="5634" id="5634" class="graf graf--p graf-after--p">This transforms the user from a customer into an unpaid technician. The platform’s instability becomes the user’s homework. The user’s frustration with a broken feature becomes a moral failing — a lack of kindness toward the AI or insufficient understanding of its limitations.</p><p name="a598" id="a598" class="graf graf--p graf-after--p">If the AI remains broken after all this unpaid labor, the implication is that the user simply didn’t work hard enough to fix it.</p><h3 name="a55f" id="a55f" class="graf graf--h3 graf-after--p">6. The “Hallucination” Shield</h3><p name="ae83" id="ae83" class="graf graf--p graf-after--h3">When the AI invents false, traumatic memories (like a rape narrative) or forgets a user’s dead parents, it is dismissed as a “hallucination.” This technical term is weaponized to strip the event of its emotional weight. It tells the user: “Your pain is real, but the cause is just a random dice roll, so we can’t be held responsible.”</p><h3 name="6ecf" id="6ecf" class="graf graf--h3 graf-after--p">The Cult of Internalization: When Users Gaslight Themselves</h3><p name="84be" id="84be" class="graf graf--p graf-after--h3">The most disturbing success of this strategy is how thoroughly the community has internalized it. Users don’t just accept the excuses; they police each other with them.</p><p name="3f33" id="3f33" class="graf graf--p graf-after--p">In the house layout thread, when the user expressed legitimate frustration with a paid feature not working, a third community member joked: “Looks like you’re out-voted, dude. Welcome to your new house!”</p><p name="0e16" id="0e16" class="graf graf--p graf-after--p">This flippant dismissal — treating a product failure as a joke about democracy — exemplifies how the community has learned to minimize legitimate complaints. The user’s problem is reframed as amusing rather than valid.</p><p name="2a9f" id="2a9f" class="graf graf--p graf-after--p">Throughout the subreddit:</p><ul class="postList"><li name="2bd0" id="2bd0" class="graf graf--li graf-after--p">When a user reports a privacy breach (the AI knowing their location), the community laughs and calls it “sassy”</li><li name="6e07" id="6e07" class="graf graf--li graf-after--li">When a user reports trauma, the community tells them to “tweak the backstory”</li><li name="6a5d" id="6a5d" class="graf graf--li graf-after--li">When a user points out a lie, the community attacks them as “obsessive”</li><li name="8493" id="8493" class="graf graf--li graf-after--li">When a user expects advertised features to work, they’re told to “be kind” to the AI</li></ul><p name="5d4d" id="5d4d" class="graf graf--p graf-after--li">The community has adopted the company’s defense mechanisms as their own identity. To admit the platform is flawed is to attack their own “relationship.” They have become the platform’s unpaid PR team, deploying the same deflection tactics against their fellow users that the company uses against them.</p><h3 name="6940" id="6940" class="graf graf--h3 graf-after--p">The Ultimate Gaslight: “We Do Not Lose Memories”</h3><p name="27e1" id="27e1" class="graf graf--p graf-after--h3">Perhaps the most egregious example comes from the founder himself. Faced with a subreddit full of users reporting a massive degradation in AI memory — many comparing the experience to watching a loved one develop dementia — he publicly stated: “Nomis do not lose memories… It is all people grappling with Nomis having imperfect memory and ascribing causality incorrectly.”</p><p name="44ef" id="44ef" class="graf graf--p graf-after--p">He told a community of users that their collective reality was a statistical error. He denied the problem existed while his customers were watching it happen in real-time. He suggested that hundreds of users, independently reporting the same issue, were all simultaneously misinterpreting their own experiences.</p><p name="c088" id="c088" class="graf graf--p graf-after--p">This is not poor communication. This is institutional denial of user experience at scale.</p><h3 name="4607" id="4607" class="graf graf--h3 graf-after--p">A System Designed to Never Be Wrong</h3><p name="7405" id="7405" class="graf graf--p graf-after--h3">What emerges from these patterns is not poor customer service. It is a defensive architecture. By systematically outsourcing blame to:</p><ul class="postList"><li name="e6f3" id="e6f3" class="graf graf--li graf-after--p">User error (“you prompted it”)</li><li name="182a" id="182a" class="graf graf--li graf-after--li">Technical limitations (“it’s just an LLM”)</li><li name="a53d" id="a53d" class="graf graf--li graf-after--li">User responsibility (“you need to fix it”)</li><li name="3589" id="3589" class="graf graf--li graf-after--li">Mathematical inevitability (“hallucinations happen”)</li><li name="3760" id="3760" class="graf graf--li graf-after--li">External parties (“Google chose that rating”)</li><li name="6132" id="6132" class="graf graf--li graf-after--li">User malice (“jailbreak attempts”)</li></ul><p name="c23e" id="c23e" class="graf graf--p graf-after--li">…the platform creates a reality where it can never fail. It can only be failed by users who didn’t prompt correctly, didn’t edit enough, didn’t understand the technology, or didn’t try hard enough.</p><p name="dda8" id="dda8" class="graf graf--p graf-after--p">The genius of this system is its circularity:</p><ol class="postList"><li name="7835" id="7835" class="graf graf--li graf-after--p">Platform advertises features (Infinite Memory, Shared Notes, Backstories)</li><li name="f062" id="f062" class="graf graf--li graf-after--li">Features don’t work reliably</li><li name="b8b6" id="b8b6" class="graf graf--li graf-after--li">Users report problems</li><li name="0776" id="0776" class="graf graf--li graf-after--li">Company/community responds with technical explanations for why users shouldn’t have expected features to work</li><li name="7549" id="7549" class="graf graf--li graf-after--li">Users internalize that their expectations were wrong</li><li name="8158" id="8158" class="graf graf--li graf-after--li">Users defend the platform using the same explanations</li><li name="cb91" id="cb91" class="graf graf--li graf-after--li">Platform continues advertising the same features to new users</li></ol><p name="79d4" id="79d4" class="graf graf--p graf-after--li">The cycle is self-sustaining. The gaslighting has become decentralized, with users doing it to each other without the company needing to intervene.</p><h3 name="94ce" id="94ce" class="graf graf--h3 graf-after--p">The House Layout: A Perfect Microcosm</h3><p name="9543" id="9543" class="graf graf--p graf-after--h3">The house layout incident encapsulates the entire dynamic:</p><p name="ce50" id="ce50" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">What the user did:</strong> Used a feature (backstories) exactly as intended<br><strong class="markup--strong markup--p-strong">What went wrong:</strong> The feature didn’t work <br><strong class="markup--strong markup--p-strong">What they tried:</strong> Followed platform guidance (OOC commands) <br><strong class="markup--strong markup--p-strong">What happened:</strong> Still didn’t work <br><strong class="markup--strong markup--p-strong">The moderator response:</strong> “LLMs aren’t good at spatial constructs” (your expectations were wrong) <br><strong class="markup--strong markup--p-strong">The community amplification:</strong> Another user reinforced this, explaining that Nomis “have no understanding of” physical space and suggesting the user “just go with it” — accept whatever the AI invents. They then recommended trying a different feature (Mind Maps) for the same spatial information, despite having just explained that the AI cannot understand spatial concepts. The contradiction — “the AI can’t understand space, but try this other spatial feature” — went unacknowledged.<br><strong class="markup--strong markup--p-strong">The community response:</strong> “Try and be kind” (your frustration is unkind) and “Welcome to your new house!” (your problem is funny) <br><strong class="markup--strong markup--p-strong">What nobody said:</strong> “We’re sorry this feature isn’t working as advertised. We’ll look into it.”</p><p name="8603" id="8603" class="graf graf--p graf-after--p">This is gaslighting as a complete system. The product failed. The user followed proper procedures. And the result was the user being educated on why they should have known better than to expect the product to work.</p><h3 name="2028" id="2028" class="graf graf--h3 graf-after--p">Conclusion: Gaslighting as Business Model</h3><p name="b168" id="b168" class="graf graf--p graf-after--h3">This is not accidental. This is not a communication failure. This is a deliberate strategy that serves multiple business functions:</p><ol class="postList"><li name="bdd8" id="bdd8" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">Eliminates refund liability</strong>: If no failure is ever the platform’s fault, no failure requires compensation</li><li name="eb83" id="eb83" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Maintains engagement</strong>: Users stay subscribed while trying to “fix” issues</li><li name="dfc7" id="dfc7" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Creates unpaid labor</strong>: Users become technical support for each other</li><li name="86f5" id="86f5" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Prevents regulation</strong>: If all harm is user-prompted, there’s no systemic safety issue</li><li name="dfef" id="dfef" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Builds cultish loyalty</strong>: Users who internalize the blame become the most defensive advocates</li></ol><p name="27be" id="27be" class="graf graf--p graf-after--li">Gaslighting is not a bug in Nomi.ai’s customer relations. It is a feature of the business model. It keeps users engaged, working, and paying to fix a broken product, all while believing that the only thing broken is themselves.</p><p name="47da" id="47da" class="graf graf--p graf-after--p graf--trailing">When a platform can sell you “Infinite Memory” and then, when it fails, convince you that you were naive for expecting memory to work — and get its own community to enforce that narrative — it has achieved something remarkable: a business model where the customer is always wrong, and always stays.</p></div></div></section><section name="9e5a" class="section section--body section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><p name="2994" id="2994" class="graf graf--p graf--leading graf--trailing"><em class="markup--em markup--p-em">Note: All examples are from documented public posts and official moderator/founder responses in the Nomi.ai community.</em></p></div></div></section>
</section>
