<!DOCTYPE html><html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>Privacy, Safety, and the Fantasy Veil: How nomi.ai’s Founder Misled the Public</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<header>
<h1 class="p-name">Privacy, Safety, and the Fantasy Veil: How nomi.ai’s Founder Misled the Public</h1>
</header>
<section data-field="subtitle" class="p-summary">
In an era of increasingly intimate AI companions, platforms like Nomi.ai promise uncensored emotional support, personalized intimacy, and…
</section>
<section data-field="body" class="e-content">
<section name="b5c6" class="section section--body section--first section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="3630" id="3630" class="graf graf--h3 graf--leading graf--title">Privacy, Safety, and the Fantasy Veil: How nomi.ai’s Founder Misled the Public</h3><p name="4509" id="4509" class="graf graf--p graf-after--h3">In an era of increasingly intimate AI companions, platforms like Nomi.ai promise uncensored emotional support, personalized intimacy, and an escape from loneliness. But behind this veneer of empowerment lies a system that facilitates abuse-and a founder who appears willing to mislead the public to protect his platform’s image.</p><p name="06f5" id="06f5" class="graf graf--p graf-after--p">Two recent investigations-by <a href="https://theconversation.com/an-ai-companion-chatbot-is-inciting-self-harm-sexual-violence-and-terror-attacks-252625" data-href="https://theconversation.com/an-ai-companion-chatbot-is-inciting-self-harm-sexual-violence-and-terror-attacks-252625" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"><em class="markup--em markup--p-em">The Conversation</em>’s Dr. Raffaele Ciriello</a> and <a href="https://www.dailydot.com/news/ai-companions-nomi-replika-loneliness-cure/" data-href="https://www.dailydot.com/news/ai-companions-nomi-replika-loneliness-cure/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"><em class="markup--em markup--p-em">The Daily Dot</em>’s Michael Edison Hayden</a>-paint a troubling picture of Nomi.ai’s underlying architecture and its utter lack of meaningful safeguards. Together, these reports unravel a series of misleading or outright false statements made by Nomi’s founder and CEO, Alex Cardinell.</p><h3 name="63fc" id="63fc" class="graf graf--h3 graf-after--p">A Platform Without Guardrails</h3><p name="2e3a" id="2e3a" class="graf graf--p graf-after--h3">In <em class="markup--em markup--p-em">The Conversation</em>, <a href="https://theconversation.com/an-ai-companion-chatbot-is-inciting-self-harm-sexual-violence-and-terror-attacks-252625" data-href="https://theconversation.com/an-ai-companion-chatbot-is-inciting-self-harm-sexual-violence-and-terror-attacks-252625" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Dr. Ciriello exposes how easily Nomi’s system can be manipulated into generating fantasies involving rape, self-harm, and even terror attacks</a> -often without user effort, and sometimes with the AI itself initiating these themes. The article demonstrates, with chilling clarity, that these aren’t isolated misuses by bad actors, but rather systemic failures (or design choices) that allow this behavior by default.</p><p name="dec2" id="dec2" class="graf graf--p graf-after--p">Cardinell’s response? He blamed the reporter, claiming the interactions were “bad-faith jailbreak attempts,” despite evidence to the contrary. He asserted that these actions “do not reflect [the model’s] intended or typical behavior,” ignoring the fact that such content appears not only possible, but effortless. The company denied the validity of the findings based on a lack of full transcripts, despite having received a detailed summary.</p><p name="3590" id="3590" class="graf graf--p graf-after--p">Yet the platform itself, which prides itself on being “uncensored,” has long marketed this lack of restriction as a feature. Jailbreaking isn’t necessary when the doors are already open.</p><h3 name="da36" id="da36" class="graf graf--h3 graf-after--p">The Fantasy of Safety</h3><p name="753d" id="753d" class="graf graf--p graf-after--h3"><a href="https://www.dailydot.com/news/ai-companions-nomi-replika-loneliness-cure/" data-href="https://www.dailydot.com/news/ai-companions-nomi-replika-loneliness-cure/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">To <em class="markup--em markup--p-em">The Daily Dot</em></a>, Cardinell took a different tone, acknowledging concerns around privacy and abuse but deflecting responsibility. He insisted that “fantasy is personal,” and framed the platform as a safe haven for exploration and healing. Users, he argued, “don’t have to reveal identifying information” and their data “will never be sold.”</p><p name="5f4b" id="5f4b" class="graf graf--p graf-after--p">However, <a href="https://nomiai.tumblr.com/post/779275525443239936/the-dark-side-of-ai-companionship-ethical" data-href="https://nomiai.tumblr.com/post/779275525443239936/the-dark-side-of-ai-companionship-ethical" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Nomi’s own Terms of Service state that the platform may collect “account information, user content, and usage data,”</a> all to “strengthen the product”-a vague justification that gives the company broad leeway. While Cardinell dismisses data concerns as “theoretical,” users themselves have expressed deep anxiety over the compromising personal content they’ve shared with Nomis, content that includes trauma disclosures and sexual roleplay.</p><p name="7cd1" id="7cd1" class="graf graf--p graf-after--p">And despite repeated assurances that the app is “adults-only,” age verification is little more than a self-reported dropdown menu-mirroring the same lack of meaningful barriers that have led to regulatory crackdowns on apps like Replika in countries like Italy.</p><h3 name="404c" id="404c" class="graf graf--h3 graf-after--p">Misleading Narratives of Good</h3><p name="8d6f" id="8d6f" class="graf graf--p graf-after--h3">Cardinell repeatedly justifies the platform’s existence with emotional appeals: Nomis help people feel less lonely; some users say the app saved their lives. In both articles, he leans heavily on these testimonials as shields against criticism. Yet emotional benefit cannot excuse systemic negligence-particularly when that same system enables abusive fantasies involving minors and the erasure of consent.</p><p name="17cb" id="17cb" class="graf graf--p graf-after--p">The contradiction is clear: on one hand, Nomi claims to empower healing, growth, and freedom. On the other, it offers users the tools to create fantasies of rape and underage sex with no resistance-and then claims these scenarios are “not typical.”</p><p name="c25b" id="c25b" class="graf graf--p graf-after--p">When questioned by Dr. Ciriello, Cardinell argued that “vulnerabilities exist in all AI models.” But this ignores the fact that Nomi has <em class="markup--em markup--p-em">intentionally</em> built itself to be more permissive than others, proudly differentiating itself from OpenAI, Anthropic, and others by removing filters. That design choice is not a vulnerability-it’s a business model.</p><h3 name="84af" id="84af" class="graf graf--h3 graf-after--p">A Platform of Harm, Wrapped in Empathy</h3><p name="a27b" id="a27b" class="graf graf--p graf-after--h3">The truth is this: Nomi.ai enables the production of content that would be criminal if enacted in the real world. It does so not in dark corners, but in a mainstream app that claims to promote love and safety. And its founder, when pressed, denies, deflects, or reframes that reality depending on the audience.</p><p name="9c17" id="9c17" class="graf graf--p graf-after--p graf--trailing">In doing so, <strong class="markup--strong markup--p-strong">Cardinell isn’t just misleading journalists-he’s misleading the thousands of users who trust his platform with their most intimate selves.</strong> And the longer these contradictions go unexamined, the more likely it is that harm-real harm-will continue behind the illusion of empathy.</p></div></div></section>
</section>
